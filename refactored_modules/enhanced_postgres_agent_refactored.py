# üî• Enhanced PostgreSQL Agent - Universal Prompt System Integration
# refactored_modules/enhanced_postgres_agent_refactored.py

import os
import time
import asyncio
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
import logging
import re
from decimal import Decimal

# Import our refactored modules
from .tenant_config import TenantConfigManager, TenantConfig
from .database_handler import DatabaseHandler
from .schema_discovery import SchemaDiscoveryService
from .business_logic_mapper import BusinessLogicMapper
from .ai_service import AIService
from .prompt_generator import PromptGenerator
from .intent_classifier import IntentClassifier

# üî• CHANGED: Import Universal Prompt System instead of Few-Shot
# from .few_shot_sql_engine import EnhancedFewShotAgent  # ‚ùå ‡πÄ‡∏≠‡∏≤‡∏≠‡∏≠‡∏Å
from .universal_prompt_system import UniversalPromptGenerator  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def convert_decimal_to_float(obj: Any) -> Any:
    """üîß Convert Decimal objects to float recursively"""
    if isinstance(obj, Decimal):
        return float(obj)
    elif isinstance(obj, dict):
        return {k: convert_decimal_to_float(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_decimal_to_float(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_decimal_to_float(item) for item in obj)
    else:
        return obj  

class EnhancedPostgresOllamaAgent:
    """üöÄ Enhanced PostgreSQL + Ollama Agent - Universal Prompt System Version"""
    
    def __init__(self):
        # Initialize all services
        self.config_manager = TenantConfigManager()
        self.tenant_configs = self.config_manager.tenant_configs
        
        self.database_handler = DatabaseHandler(self.tenant_configs)
        self.schema_service = SchemaDiscoveryService()
        self.business_mapper = BusinessLogicMapper()
        self.ai_service = AIService()
        self.prompt_generator = PromptGenerator(self.schema_service, self.business_mapper)
        self.intent_classifier = IntentClassifier()
        
        # üî• CHANGED: Use Universal Prompt System instead of Few-Shot
        self.universal_prompt_generator = UniversalPromptGenerator()
        
        logger.info("‚úÖ Enhanced PostgreSQL Ollama Agent initialized with Universal Prompt System")

    async def process_enhanced_question(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """Enhanced question processing with Universal Prompt System"""
        if tenant_id not in self.tenant_configs:
            return {
                "answer": f"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å tenant: {tenant_id}",
                "success": False,
                "data_source_used": "error",
                "confidence": "none"
            }

        config = self.tenant_configs[tenant_id]
        start_time = datetime.now()
        
        # üî• ‡πÉ‡∏ä‡πâ Intent Classifier ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô
        intent_result = self.intent_classifier.classify_intent(question)
        logger.info(f"Intent classification for '{question}': {intent_result}")
        
        # üéØ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ SQL
        if not intent_result['should_use_sql']:
            return await self._handle_non_sql_question(
                question, tenant_id, intent_result, config
            )
        
        # üóÑÔ∏è ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ SQL - ‡πÉ‡∏ä‡πâ Universal Prompt System
        try:
            # 1. Enhanced SQL generation with Universal Prompt
            sql_query, sql_metadata = await self.generate_enhanced_sql(question, tenant_id)
            
            # 2. Execute SQL query
            db_results = self.database_handler.execute_sql_query(tenant_id, sql_query)
            
            # 3. Convert Decimal to float before JSON serialization
            processed_results = self.database_handler.process_decimal_data(db_results)
            
            # 4. Enhanced interpretation
            schema_info = self.schema_service.get_schema_info(tenant_id)
            interpretation_prompt = self.prompt_generator.create_enhanced_interpretation_prompt(
                question, sql_query, processed_results, config, schema_info
            )
            
            ai_response = await self.ai_service.call_ollama_api(
                config, interpretation_prompt, temperature=0.3
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "answer": ai_response,
                "success": True,
                "data_source_used": f"universal_prompt_{config.model_name}",  # üî• CHANGED
                "sql_query": sql_query,
                "db_results_count": len(processed_results),
                "tenant_id": tenant_id,
                "model_used": config.model_name,
                "sql_generation_method": sql_metadata["method"],  # üî• ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô "universal_prompt_system"
                "confidence": sql_metadata["confidence"],
                "processing_time_seconds": processing_time,
                "intent_detected": intent_result['intent'],
                "enhancement_version": "3.0_universal_prompt"  # üî• CHANGED
            }
            
        except Exception as e:
            logger.error(f"Universal Prompt processing failed for {tenant_id}: {e}")
            
            # Enhanced fallback
            try:
                fallback_prompt = self._create_enhanced_fallback_prompt(question, tenant_id)
                ai_response = await self.ai_service.call_ollama_api(config, fallback_prompt)
                
                processing_time = (datetime.now() - start_time).total_seconds()
                
                return {
                    "answer": ai_response,
                    "success": True,
                    "data_source_used": f"enhanced_fallback_{config.model_name}",
                    "error": str(e),
                    "fallback_mode": True,
                    "confidence": "low",
                    "processing_time_seconds": processing_time,
                    "intent_detected": intent_result['intent'],
                    "enhancement_version": "3.0_universal_prompt_fallback"
                }
            except Exception as ai_error:
                return {
                    "answer": f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {str(e)}",
                    "success": False,
                    "data_source_used": "error",
                    "error": str(ai_error),
                    "confidence": "none"
                }

    async def process_enhanced_question_streaming(self, question: str, tenant_id: str):
        """üî• Fixed streaming version with Universal Prompt System"""
        if tenant_id not in self.tenant_configs:
            yield {
                "type": "error",
                "message": f"‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å tenant: {tenant_id}"
            }
            return

        config = self.tenant_configs[tenant_id]
        start_time = datetime.now()

        try:
            # üìä Step 1: Generate SQL with Universal Prompt
            yield {
                "type": "status",
                "message": "üéØ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á SQL Query ‡∏î‡πâ‡∏ß‡∏¢ Universal Prompt System...",
                "step": "universal_sql_generation"
            }
            
            sql_query, sql_metadata = await self.generate_enhanced_sql(question, tenant_id)
            
            yield {
                "type": "sql_generated",
                "sql_query": sql_query,
                "method": sql_metadata["method"],  # "universal_prompt_system"
                "confidence": sql_metadata["confidence"]
            }

            # üóÑÔ∏è Step 2: Execute SQL
            yield {
                "type": "status", 
                "message": "üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...",
                "step": "database_query"
            }
            
            db_results = self.database_handler.execute_sql_query(tenant_id, sql_query)
            
            # üîß FIX: Process Decimal data BEFORE yielding
            processed_results = self.database_handler.process_decimal_data(db_results)
            
            # üîß FIX: Convert any remaining Decimals in preview
            safe_preview = []
            for item in processed_results[:3]:
                safe_item = convert_decimal_to_float(item)
                safe_preview.append(safe_item)
            
            yield {
                "type": "db_results",
                "count": len(processed_results),
                "preview": safe_preview
            }

            # ü§ñ Step 3: Create interpretation prompt
            schema_info = self.schema_service.get_schema_info(tenant_id)
            interpretation_prompt = self.prompt_generator.create_enhanced_interpretation_prompt(
                question, sql_query, processed_results, config, schema_info
            )

            # üî• Step 4: Stream AI response
            yield {
                "type": "status",
                "message": "ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°...",
                "step": "ai_processing"
            }
            
            yield {"type": "answer_start"}

            # Stream the AI response token by token
            async for token in self.ai_service.call_ollama_api_streaming(
                config, interpretation_prompt, temperature=0.3
            ):
                yield {
                    "type": "answer_chunk",
                    "content": token
                }

            # ‚úÖ Final metadata
            processing_time = (datetime.now() - start_time).total_seconds()
            
            yield {
                "type": "answer_complete",
                "sql_query": sql_query,
                "db_results_count": len(processed_results),
                "sql_generation_method": sql_metadata["method"],  # "universal_prompt_system"
                "confidence": sql_metadata["confidence"],
                "processing_time_seconds": processing_time,
                "tenant_id": tenant_id,
                "model_used": config.model_name
            }

        except Exception as e:
            logger.error(f"Universal Prompt streaming processing failed for {tenant_id}: {e}")
            yield {
                "type": "error",
                "message": f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Universal Prompt: {str(e)}"
            }

    async def generate_enhanced_sql(self, question: str, tenant_id: str) -> Tuple[str, Dict[str, Any]]:
        """üéØ Enhanced SQL generation with Universal Prompt System"""
        
        try:
            logger.info(f"üéØ Using Universal Prompt System for: {question[:50]}...")
            
            # üî• CHANGED: Use Universal Prompt instead of Few-Shot
            sql_query, metadata = await self.universal_prompt_generator.generate_sql_with_universal_prompt(
                question, tenant_id, self
            )
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ SQL ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡πÑ‡∏´‡∏°
            if self._is_high_quality_sql(sql_query, question):
                logger.info(f"‚úÖ Universal Prompt Success! Method: {metadata['method']}")
                return sql_query, metadata
            else:
                logger.warning("üîÑ Universal Prompt SQL quality insufficient, falling back...")
                
        except Exception as e:
            logger.warning(f"üîÑ Universal Prompt failed: {e}, falling back to original method")
        
        # Fallback to original enhanced method
        return await self.original_generate_enhanced_sql(question, tenant_id)

    async def original_generate_enhanced_sql(self, question: str, tenant_id: str) -> Tuple[str, Dict[str, Any]]:
        """Enhanced SQL generation with business intelligence and pattern matching (Original Method)"""
        
        config = self.tenant_configs[tenant_id]
        schema_info = self.schema_service.get_schema_info(tenant_id)
        business_logic = self.business_mapper.get_business_logic(tenant_id)
        
        # Analyze question for intent and patterns
        query_analysis = self._analyze_question_intent(question, tenant_id)
        
        # Check for pre-defined patterns
        if query_analysis['pattern_match']:
            sql_query = self._apply_sql_pattern(query_analysis, tenant_id)
            metadata = {
                'method': 'pattern_matching_original',
                'pattern_used': query_analysis['pattern_match'],
                'confidence': 'high'
            }
            return sql_query, metadata
        
        # Generate enhanced system prompt
        system_prompt = self.prompt_generator.create_enhanced_sql_prompt(
            question, schema_info, business_logic, config
        )
        
        try:
            # Call AI with enhanced prompt
            ai_response = await self.ai_service.call_ollama_api(
                tenant_config=config,
                prompt=system_prompt,
                context_data="",
                temperature=0.1
            )
            
            # Extract and validate SQL
            sql_query = self._extract_and_validate_sql(ai_response, tenant_id)
            
            metadata = {
                'method': 'ai_generation_original',
                'original_response': ai_response[:200],
                'confidence': 'medium' if len(sql_query) > 50 else 'low'
            }
            
            return sql_query, metadata
            
        except Exception as e:
            logger.error(f"Original enhanced SQL generation failed: {e}")
            fallback_sql = self._generate_fallback_sql(question, tenant_id)
            metadata = {
                'method': 'fallback_original', 
                'error': str(e),
                'confidence': 'low'
            }
            return fallback_sql, metadata

    def _is_high_quality_sql(self, sql: str, question: str) -> bool:
        """üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û SQL ‡∏ó‡∏µ‡πà Universal Prompt ‡∏™‡∏£‡πâ‡∏≤‡∏á"""
        sql_upper = sql.upper()
        question_lower = question.lower()
        
        # Basic validation
        if not sql_upper.startswith('SELECT'):
            return False
        
        if '‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô' in question_lower and '‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö' in question_lower:
            if 'LEFT JOIN' not in sql_upper:
                logger.warning("‚ùå Assignment query without LEFT JOIN")
                return False
            
            if 'COALESCE' not in sql_upper:
                logger.warning("‚ùå Assignment query without COALESCE for NULL handling")
                return False
        
        dangerous_patterns = [
            'AND.*OR.*ORDER',
            'SELECT \\*',
            'WHERE.*ILIKE.*AND.*ILIKE.*OR'
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, sql, re.IGNORECASE):
                logger.warning(f"‚ùå Found dangerous pattern: {pattern}")
                return False
        
        return True

    def get_universal_prompt_stats(self) -> Dict[str, Any]:
        """üìä ‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Universal Prompt System"""
        if hasattr(self, 'universal_prompt_generator'):
            stats = self.universal_prompt_generator.get_statistics()
            
            return {
                "universal_prompt_enabled": True,
                "version": "3.0",
                "companies_supported": len(self.universal_prompt_generator.company_profiles),
                "business_types": [
                    profile.business_type 
                    for profile in self.universal_prompt_generator.company_profiles.values()
                ],
                "templates_available": len(self.universal_prompt_generator.prompt_templates),
                "pattern_matchers": len(self.universal_prompt_generator.pattern_matchers),
                "status": "active",
                **stats
            }
        else:
            return {
                "universal_prompt_enabled": False,
                "error": "Universal Prompt System not initialized"
            }

    # üîß Keep all existing methods (unchanged)
    def _analyze_question_intent(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """Analyze question to determine intent and suggest patterns"""
        question_lower = question.lower()
        
        # Common intent patterns
        intents = {
            'employee_count': ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô', 'how many employees', 'employee count'],
            'salary_info': ['‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏Ñ‡πà‡∏≤‡∏à‡πâ‡∏≤‡∏á', 'salary', 'pay', 'earning'],
            'project_budget': ['‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì', '‡∏ö‡∏±‡∏î‡πÄ‡∏à‡∏ï', 'budget', 'cost', 'price'],
            'top_performers': ['‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î', '‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î', '‡πÄ‡∏Å‡πà‡∏á', '‡∏î‡∏µ', 'top', 'best', 'highest'],
            'department_analysis': ['‡πÅ‡∏ú‡∏ô‡∏Å', '‡∏ù‡πà‡∏≤‡∏¢', 'department', 'division', 'team'],
            'project_status': ['‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project', '‡∏á‡∏≤‡∏ô', 'work', 'status'],
            'client_info': ['‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤', 'client', 'customer', '‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó']
        }
        
        detected_intents = []
        for intent, keywords in intents.items():
            if any(keyword in question_lower for keyword in keywords):
                detected_intents.append(intent)
        
        # Pattern matching logic
        pattern_match = None
        if 'employee_count' in detected_intents and 'department_analysis' in detected_intents:
            pattern_match = 'employee_count_by_department'
        elif 'salary_info' in detected_intents and 'top_performers' in detected_intents:
            pattern_match = 'top_earners'
        elif 'project_budget' in detected_intents and 'top_performers' in detected_intents:
            pattern_match = 'high_budget_projects'
        
        return {
            'intents': detected_intents,
            'pattern_match': pattern_match,
            'complexity': len(detected_intents),
            'question_type': 'analytical' if len(detected_intents) > 1 else 'simple'
        }

    def _apply_sql_pattern(self, query_analysis: Dict, tenant_id: str) -> str:
        """Apply pre-defined SQL patterns for common queries"""
        pattern = query_analysis['pattern_match']
        sql_template = self.business_mapper.get_sql_pattern(pattern)
        
        if pattern == 'top_earners':
            return sql_template.format(limit=5)
        elif pattern == 'high_budget_projects':
            # Different thresholds based on tenant
            thresholds = {
                'company-a': 2000000,  # 2M THB for enterprise
                'company-b': 500000,   # 500k THB for regional  
                'company-c': 1500000   # 1.5M USD for international
            }
            return sql_template.format(threshold=thresholds.get(tenant_id, 1000000))
        elif pattern == 'employee_project_allocation':
            return sql_template.format(where_condition='p.status = \'active\'')
        
        return sql_template

    def _extract_and_validate_sql(self, ai_response: str, tenant_id: str) -> str:
        """Enhanced SQL extraction with validation"""
        # Remove markdown code blocks
        cleaned = ai_response.strip()
        
        # Extract SQL from various formats
        sql_patterns = [
            r'```sql\s*(.*?)\s*```',
            r'```\s*(SELECT.*?;)\s*```',
            r'(SELECT.*?;)',
            r'(WITH.*?;)',
            r'(INSERT.*?;)',
            r'(UPDATE.*?;)',
            r'(DELETE.*?;)'
        ]
        
        for pattern in sql_patterns:
            match = re.search(pattern, cleaned, re.DOTALL | re.IGNORECASE)
            if match:
                sql = match.group(1).strip()
                
                # Validate SQL
                if self.database_handler.validate_sql_query(sql, tenant_id):
                    return sql
        
        # If no valid SQL found, try line-by-line extraction
        lines = cleaned.split('\n')
        sql_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and not line.startswith('--'):
                if any(keyword in line.upper() for keyword in ['SELECT', 'FROM', 'WHERE', 'JOIN', 'GROUP', 'ORDER', 'HAVING']):
                    sql_lines.append(line)
                elif sql_lines and line.endswith(';'):
                    sql_lines.append(line)
                    break
                elif sql_lines:
                    sql_lines.append(line)
        
        if sql_lines:
            sql_query = ' '.join(sql_lines)
            # Clean up and validate
            sql_query = ' '.join(sql_query.split())
            if not sql_query.rstrip().endswith(';'):
                sql_query += ';'
            
            if self.database_handler.validate_sql_query(sql_query, tenant_id):
                return sql_query
        
        # Final fallback
        return self._generate_fallback_sql("Unable to generate SQL", tenant_id)

    def _generate_fallback_sql(self, question: str, tenant_id: str) -> str:
        """Generate safe fallback SQL when AI generation fails"""
        # Simple fallback based on question keywords
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô', 'employee', '‡∏Ñ‡∏ô', 'people']):
            return "SELECT name, position, department FROM employees ORDER BY hire_date DESC LIMIT 10;"
        elif any(word in question_lower for word in ['‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project', '‡∏á‡∏≤‡∏ô', 'work']):
            return "SELECT name, client, status FROM projects ORDER BY start_date DESC LIMIT 10;"
        elif any(word in question_lower for word in ['‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', 'salary', '‡∏Ñ‡πà‡∏≤‡∏à‡πâ‡∏≤‡∏á', 'pay']):
            return "SELECT name, position, salary FROM employees ORDER BY salary DESC LIMIT 10;"
        elif any(word in question_lower for word in ['‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì', 'budget', '‡∏ö‡∏±‡∏î‡πÄ‡∏à‡∏ï', 'cost']):
            return "SELECT name, client, budget FROM projects ORDER BY budget DESC LIMIT 10;"
        else:
            return "SELECT '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á SQL ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á' as message LIMIT 1;"

    async def _handle_non_sql_question(self, question: str, tenant_id: str, 
                                    intent_result: dict, config: TenantConfig) -> Dict[str, Any]:
        """üî• Handle non-SQL questions with AI-generated responses"""
        
        intent = intent_result['intent']
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á context-aware prompt ‡∏ï‡∏≤‡∏° intent
        if intent == 'greeting':
            context_prompt = self._create_greeting_prompt(config)
        elif intent == 'help':
            context_prompt = self._create_help_prompt(config)
        else:
            context_prompt = self._create_general_conversation_prompt(question, config)
        
        # üî• ‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
        ai_response = await self.ai_service.call_ollama_api(
            tenant_config=config,
            prompt=context_prompt,
            context_data="",
            temperature=0.7  # ‡πÉ‡∏ä‡πâ temperature ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
        )
        
        return {
            "answer": ai_response,
            "success": True,
            "data_source_used": f"conversational_{config.model_name}",
            "intent_detected": intent,
            "intent_confidence": intent_result['confidence'],
            "sql_used": False,
            "processing_type": "ai_conversational",
            "tenant_id": tenant_id,
            "enhancement_version": "3.0_universal_prompt"
        }

    def _create_greeting_prompt(self, config: TenantConfig) -> str:
        """Create context-aware greeting prompt for AI"""
        
        if config.language == 'th':
            return f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á {config.name}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó:
- ‡∏ä‡∏∑‡πà‡∏≠: {config.name}
- ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏á‡∏≤‡∏ô: {config.business_type}
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç: ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ

‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
- ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ï‡πà‡∏≤‡∏á‡πÜ

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ:
‚Ä¢ ‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏Å
‚Ä¢ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
‚Ä¢ ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏´‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏∏‡∏ì ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á:"""
        
        else:  # English
            return f"""You are a friendly and helpful AI Assistant for {config.name}

Company Information:
- Name: {config.name}
- Business: {config.business_type}
- Expertise: Software development and technology solutions

Your Capabilities:
- Analyze employee and project data
- Answer questions about business operations
- Generate reports and statistics

Example questions you can answer:
‚Ä¢ How many employees are in each department?
‚Ä¢ Which projects have the highest budgets?
‚Ä¢ Which employees work on multiple projects?

The user is greeting you. Please respond in a friendly manner, introduce yourself, and explain how you can help:"""

    def _create_help_prompt(self, config: TenantConfig) -> str:
        """Create help prompt for AI"""
        
        if config.language == 'th':
            return f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏Ç‡∏≠‡∏á {config.name} ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó:
- ‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: {config.business_type}
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ: ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô, ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ, ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì, ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤, ‡πÅ‡∏ú‡∏ô‡∏Å‡∏ï‡πà‡∏≤‡∏á‡πÜ

‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÑ‡∏î‡πâ:
1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô, ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô, ‡πÅ‡∏ú‡∏ô‡∏Å, ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á)
2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ (‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞, ‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô, ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤)
3. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û (KPI, ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥, ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°)
4. ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:"""
        
        else:
            return f"""You are an AI Assistant for {config.name}. The user is asking what you can help with.

Company Context:
- Business Type: {config.business_type}
- Available Data: employees, projects, budgets, clients, departments

Types of analysis you can perform:
1. Employee data (count, salaries, departments, positions)
2. Project information (budgets, status, teams, clients)
3. Performance analysis (KPIs, statistics, trends)
4. Executive reports

Please explain your capabilities clearly and provide useful example questions:"""

    def _create_general_conversation_prompt(self, question: str, config: TenantConfig) -> str:
        """Create prompt for general conversation"""
        
        if config.language == 'th':
            return f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡∏Ç‡∏≠‡∏á {config.name}

‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤:
- ‡∏ä‡∏∑‡πà‡∏≠: {config.name}
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: {config.business_type}
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç: ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {question}

‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ
‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á SQL ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:"""
        
        else:
            return f"""You are a friendly AI Assistant for {config.name}

Our Company:
- Name: {config.name}
- Business Type: {config.business_type}
- Expertise: Software development and technology solutions

User Question: {question}

If the question relates to company data, suggest that you can help analyze information
If it's a general question, respond in a friendly and helpful manner
Don't try to generate SQL or access databases:"""

    def _create_enhanced_fallback_prompt(self, question: str, tenant_id: str) -> str:
        """Create enhanced fallback prompt with business context"""
        config = self.tenant_configs[tenant_id]
        schema_info = self.schema_service.get_schema_info(tenant_id)
        
        if config.language == 'en':
            return f"""As a business consultant for {config.name}, please answer this question using your knowledge about {config.business_type} operations.

Company Context:
- Business Focus: {schema_info.get('business_context', {}).get('primary_focus', 'N/A')}
- Client Type: {schema_info.get('business_context', {}).get('client_profile', 'N/A')}
- Project Scale: {schema_info.get('business_context', {}).get('project_scale', 'N/A')}

Question: {question}

Note: Direct database access is temporarily unavailable. Please provide helpful insights based on typical {config.business_type} operations and best practices.

Provide a professional, informative response:"""
        else:
            return f"""‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {config.name} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô {config.business_type}

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó:
- ‡∏à‡∏∏‡∏î‡πÄ‡∏ô‡πâ‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: {schema_info.get('business_context', {}).get('primary_focus', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {schema_info.get('business_context', {}).get('client_profile', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}
- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ: {schema_info.get('business_context', {}).get('project_scale', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô {config.business_type} ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏î‡∏µ

‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:"""


# üß™ Test Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Universal Prompt Integration
async def test_universal_prompt_integration():
    """üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Universal Prompt Integration ‡∏Å‡∏±‡∏ö Enhanced Agent"""
    agent = EnhancedPostgresOllamaAgent()
    
    test_scenarios = [
        {
            "tenant": "company-a",
            "questions": [
                "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",  # Should be conversational
                "‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏Å",  # Should use Universal Prompt
                "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"  # Should use Universal Prompt
            ]
        },
        {
            "tenant": "company-b", 
            "questions": [
                "‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á",  # Should use Universal Prompt (Tourism)
                "‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡∏°‡∏µ‡∏Å‡∏µ‡πà‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ"  # Should use Universal Prompt (Tourism)
            ]
        },
        {
            "tenant": "company-c",
            "questions": [
                "Which projects have highest USD budget",  # Should use Universal Prompt (International)
                "How many international employees"  # Should use Universal Prompt (International)
            ]
        }
    ]
    
    print("üß™ Testing Universal Prompt System Integration")
    print("=" * 70)
    
    for scenario in test_scenarios:
        print(f"\nüè¢ Testing {scenario['tenant'].upper()}")
        print("-" * 50)
        
        for question in scenario['questions'][:2]:  # Test only 2 questions per tenant
            print(f"\n‚ùì Question: {question}")
            
            result = await agent.process_enhanced_question(question, scenario['tenant'])
            
            # Extract key information
            success = result.get('success', False)
            sql_method = result.get('sql_generation_method', 'N/A')
            data_source = result.get('data_source_used', 'N/A')
            fallback_mode = result.get('fallback_mode', False)
            sql_query = result.get('sql_query')
            
            # Determine status
            if 'universal_prompt' in sql_method:
                status = "‚úÖ UNIVERSAL PROMPT SUCCESS"
            elif sql_method == 'few_shot_learning':
                status = "‚ö†Ô∏è USING FEW-SHOT (Not Universal)"
            elif fallback_mode:
                status = "‚ùå FALLBACK MODE"
            elif 'conversational' in data_source:
                status = "üí¨ CONVERSATIONAL (Expected)"
            else:
                status = "‚ùì UNKNOWN METHOD"
            
            print(f"   {status}")
            print(f"   Success: {success}")
            print(f"   SQL Method: {sql_method}")
            print(f"   Data Source: {data_source}")
            print(f"   Has SQL: {'Yes' if sql_query else 'No'}")
            print(f"   Answer: {result['answer'][:100]}...")
    
    # Test Universal Prompt Statistics
    print(f"\nüìä Universal Prompt System Statistics:")
    print("-" * 50)
    
    try:
        stats = agent.get_universal_prompt_stats()
        print(f"   Enabled: {stats.get('universal_prompt_enabled', False)}")
        print(f"   Version: {stats.get('version', 'N/A')}")
        print(f"   Companies: {stats.get('companies_supported', 0)}")
        print(f"   Status: {stats.get('status', 'N/A')}")
    except Exception as e:
        print(f"   ‚ùå Error getting stats: {e}")

if __name__ == "__main__":
    print("üöÄ Enhanced PostgreSQL Ollama Agent - Universal Prompt Integration")
    print("üéØ Now using Universal Prompt System instead of Few-Shot Learning")
    asyncio.run(test_universal_prompt_integration())