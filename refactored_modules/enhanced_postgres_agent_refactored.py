# refactored_modules/enhanced_postgres_agent_refactored.py
# üîÑ FIXED VERSION: Enhanced Intent Detection + Real-time Schema Discovery

import os
import time
import re
import json
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
import logging
from decimal import Decimal

# Import essential modules
from .tenant_config import TenantConfigManager, TenantConfig
from .database_handler import DatabaseHandler
from .ai_service import AIService

# üÜï Import PromptManager
try:
    from core_system.prompt_manager import WorkingPromptManager
    PROMPT_MANAGER_AVAILABLE = True
except ImportError:
    PROMPT_MANAGER_AVAILABLE = False
    logging.warning("‚ö†Ô∏è PromptManager not available, using fallback prompts")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EnhancedIntentDetector:
    """üéØ Enhanced Intent Detection System"""
    
    def __init__(self):
        # ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ SQL ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        self.sql_indicators = {
            'identification': ['‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà', '‡πÉ‡∏Ñ‡∏£‡πÄ‡∏õ‡πá‡∏ô', '‡πÉ‡∏Ñ‡∏£‡∏ó‡∏≥', 'who is', 'who are', 'who works'],
            'listing': ['‡πÉ‡∏Ñ‡∏£‡∏ö‡πâ‡∏≤‡∏á', '‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠', 'list', '‡πÅ‡∏™‡∏î‡∏á', 'show me', 'display'],
            'counting': ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many', 'count', '‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£', '‡∏°‡∏µ‡∏Å‡∏µ‡πà'],
            'searching': ['‡∏´‡∏≤', '‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤', 'find', 'search', '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á', 'position'],
            'filtering': ['‡πÅ‡∏ú‡∏ô‡∏Å', 'department', '‡∏ù‡πà‡∏≤‡∏¢', '‡∏á‡∏≤‡∏ô', '‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project'],
            'analysis': ['‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', '‡∏™‡∏£‡∏∏‡∏õ', 'analyze', 'compare']
        }
        
        # ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Conversational ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        self.conversational_indicators = {
            'greetings': ['‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ', 'hello', 'hi', '‡∏ä‡πà‡∏ß‡∏¢', 'help'],
            'general_info': ['‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£', '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö', 'about', 'what are you'],
            'capabilities': ['‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ', '‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£', 'what can you do']
        }
    
    def detect_intent(self, question: str) -> Dict[str, Any]:
        """üéØ Enhanced Intent Detection with confidence scoring"""
        
        question_lower = question.lower()
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô SQL indicators
        sql_score = 0
        sql_reasons = []
        
        for category, keywords in self.sql_indicators.items():
            matches = [word for word in keywords if word in question_lower]
            if matches:
                # ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                weight = 3 if category in ['identification', 'counting'] else 2
                sql_score += len(matches) * weight
                sql_reasons.append(f"{category}: {matches}")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Conversational indicators
        conv_score = 0
        conv_reasons = []
        
        for category, keywords in self.conversational_indicators.items():
            matches = [word for word in keywords if word in question_lower]
            if matches:
                conv_score += len(matches) * 3  # ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏π‡∏á
                conv_reasons.append(f"{category}: {matches}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Pattern ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        specific_patterns = self._check_specific_patterns(question_lower)
        if specific_patterns['sql_pattern']:
            sql_score += 5
            sql_reasons.append(f"pattern: {specific_patterns['sql_pattern']}")
        
        if specific_patterns['conv_pattern']:
            conv_score += 5
            conv_reasons.append(f"pattern: {specific_patterns['conv_pattern']}")
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à Intent
        total_score = sql_score + conv_score
        
        if total_score == 0:
            return {
                'intent': 'unknown',
                'confidence': 0.0,
                'sql_score': sql_score,
                'conv_score': conv_score,
                'reasons': ['No clear indicators found']
            }
        
        if conv_score > sql_score:
            return {
                'intent': 'conversational',
                'confidence': conv_score / total_score,
                'sql_score': sql_score,
                'conv_score': conv_score,
                'reasons': conv_reasons
            }
        else:
            return {
                'intent': 'sql_query',
                'confidence': sql_score / total_score,
                'sql_score': sql_score,
                'conv_score': conv_score,
                'reasons': sql_reasons
            }
    
    def _check_specific_patterns(self, question_lower: str) -> Dict[str, str]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Pattern ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å Intent ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"""
        
        # Patterns ‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å SQL ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        sql_patterns = [
            r'‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà.*‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á',  # "‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á frontend ‡∏ö‡πâ‡∏≤‡∏á"
            r'‡∏°‡∏µ.*‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô.*‡πÅ‡∏ú‡∏ô‡∏Å',    # "‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å IT"
            r'‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠.*‡∏ó‡∏µ‡πà',       # "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà..."
            r'‡πÅ‡∏™‡∏î‡∏á.*‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',       # "‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô"
            r'who.*in.*position',  # "who is in position"
            r'how many.*in'        # "how many people in"
        ]
        
        # Patterns ‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å Conversational ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        conv_patterns = [
            r'‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ.*‡∏Ñ‡∏£‡∏±‡∏ö',       # "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
            r'‡∏Ñ‡∏∏‡∏ì.*‡∏Ñ‡∏∑‡∏≠.*‡πÉ‡∏Ñ‡∏£',      # "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö"
            r'‡∏ä‡πà‡∏ß‡∏¢.*‡∏≠‡∏∞‡πÑ‡∏£.*‡πÑ‡∏î‡πâ',    # "‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á"
            r'hello.*there',       # "hello there"
            r'what.*are.*you'      # "what are you"
        ]
        
        for pattern in sql_patterns:
            if re.search(pattern, question_lower):
                return {'sql_pattern': pattern, 'conv_pattern': None}
        
        for pattern in conv_patterns:
            if re.search(pattern, question_lower):
                return {'conv_pattern': pattern, 'sql_pattern': None}
        
        return {'sql_pattern': None, 'conv_pattern': None}

class SchemaInspector:
    """üîç Real-time Schema Discovery and Analysis"""
    
    def __init__(self, database_handler: DatabaseHandler):
        self.database_handler = database_handler
        self.schema_cache = {}
        self.cache_ttl = 3600  # 1 hour
    
    async def get_live_schema_info(self, tenant_id: str) -> Dict[str, Any]:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Schema ‡πÅ‡∏ö‡∏ö Real-time ‡∏û‡∏£‡πâ‡∏≠‡∏° Cache"""
        
        cache_key = f"{tenant_id}_schema"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Cache
        if self._is_cache_valid(cache_key):
            logger.info(f"üìä Using cached schema for {tenant_id}")
            return self.schema_cache[cache_key]['data']
        
        try:
            logger.info(f"üîç Discovering live schema for {tenant_id}")
            schema_info = await self._discover_schema(tenant_id)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Cache
            self.schema_cache[cache_key] = {
                'data': schema_info,
                'timestamp': time.time()
            }
            
            return schema_info
            
        except Exception as e:
            logger.error(f"‚ùå Schema discovery failed for {tenant_id}: {e}")
            return self._get_fallback_schema()
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Cache ‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        if cache_key not in self.schema_cache:
            return False
        
        cache_age = time.time() - self.schema_cache[cache_key]['timestamp']
        return cache_age < self.cache_ttl
    
    async def _discover_schema(self, tenant_id: str) -> Dict[str, Any]:
        """‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á"""
        
        try:
            conn = self.database_handler.get_database_connection(tenant_id)
            cursor = conn.cursor()
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            cursor.execute("""
                SELECT table_name, column_name, data_type, is_nullable
                FROM information_schema.columns 
                WHERE table_schema = 'public' 
                AND table_name IN ('employees', 'projects', 'employee_projects')
                ORDER BY table_name, ordinal_position
            """)
            
            schema_info = {
                'tables': {},
                'sample_data': {},
                'discovered_at': datetime.now().isoformat()
            }
            
            # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            for row in cursor.fetchall():
                table_name, column_name, data_type, is_nullable = row
                
                if table_name not in schema_info['tables']:
                    schema_info['tables'][table_name] = {
                        'columns': [],
                        'primary_key': None
                    }
                
                schema_info['tables'][table_name]['columns'].append({
                    'name': column_name,
                    'type': data_type,
                    'nullable': is_nullable == 'YES'
                })
            
            # ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            for table_name in schema_info['tables'].keys():
                sample_data = await self._get_sample_data(cursor, table_name)
                schema_info['sample_data'][table_name] = sample_data
            
            conn.close()
            return schema_info
            
        except Exception as e:
            logger.error(f"Schema discovery error: {e}")
            raise
    
    async def _get_sample_data(self, cursor, table_name: str) -> Dict[str, List]:
        """‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        
        sample_data = {}
        
        try:
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            cursor.execute(f"""
                SELECT column_name FROM information_schema.columns 
                WHERE table_name = '{table_name}' AND table_schema = 'public'
                ORDER BY ordinal_position
            """)
            
            columns = [row[0] for row in cursor.fetchall()]
            
            # ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
            important_columns = ['department', 'position', 'name', 'client', 'status']
            
            for column in columns:
                if column in important_columns:
                    cursor.execute(f"""
                        SELECT DISTINCT {column} 
                        FROM {table_name} 
                        WHERE {column} IS NOT NULL 
                        LIMIT 5
                    """)
                    
                    values = [str(row[0]) for row in cursor.fetchall()]
                    sample_data[column] = values
            
            return sample_data
            
        except Exception as e:
            logger.warning(f"Could not get sample data for {table_name}: {e}")
            return {}
    
    def _get_fallback_schema(self) -> Dict[str, Any]:
        """Schema ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏î‡πâ"""
        return {
            'tables': {
                'employees': {
                    'columns': [
                        {'name': 'id', 'type': 'integer', 'nullable': False},
                        {'name': 'name', 'type': 'character varying', 'nullable': False},
                        {'name': 'department', 'type': 'character varying', 'nullable': False},
                        {'name': 'position', 'type': 'character varying', 'nullable': False},
                        {'name': 'salary', 'type': 'numeric', 'nullable': False}
                    ]
                }
            },
            'sample_data': {},
            'discovered_at': datetime.now().isoformat(),
            'fallback': True
        }

class EnhancedPostgresOllamaAgent:
    """üéØ Enhanced PostgreSQL Agent with Fixed Intent Detection and Real-time Schema Discovery"""
    
    def __init__(self):
        """üèóÔ∏è Initialize with enhanced components"""
        self.config_manager = TenantConfigManager()
        self.tenant_configs = self.config_manager.tenant_configs
        self.database_handler = DatabaseHandler(self.tenant_configs)
        self.ai_service = AIService()
        
        # üÜï Enhanced components
        self.intent_detector = EnhancedIntentDetector()
        self.schema_inspector = SchemaInspector(self.database_handler)
        
        # üÜï Initialize PromptManager
        self.prompt_manager = None
        self.use_prompt_manager = False
        self._init_prompt_manager()
        
        # Statistics tracking
        self.stats = {
            'total_queries': 0,
            'sql_queries': 0,
            'conversational_queries': 0,
            'intent_accuracy': []
        }
        
        logger.info(f"‚úÖ Enhanced PostgreSQL Agent initialized with fixes")
        logger.info(f"üéØ Intent Detection: Enhanced multi-pattern system")
        logger.info(f"üîç Schema Discovery: Real-time with caching")
        logger.info(f"üéØ PromptManager: {'‚úÖ Active' if self.use_prompt_manager else '‚ùå Fallback mode'}")
    
    def _init_prompt_manager(self):
        """üîß Initialize PromptManager with proper error handling"""
        
        if not PROMPT_MANAGER_AVAILABLE:
            logger.warning("‚ö†Ô∏è PromptManager module not available")
            return
        
        try:
            # üîß Convert TenantConfig objects to dictionaries
            tenant_config_dicts = {}
            for tenant_id, config in self.tenant_configs.items():
                tenant_config_dicts[tenant_id] = {
                    'company_id': tenant_id,
                    'name': config.name,
                    'model': config.model_name,
                    'language': config.language,
                    'business_type': config.business_type,
                    'db_host': config.db_host,
                    'db_port': config.db_port,
                    'db_name': config.db_name,
                    'db_user': config.db_user,
                    'db_password': config.db_password
                }
            
            self.prompt_manager = WorkingPromptManager(tenant_config_dicts)
            
            # Check if any prompts loaded successfully
            stats = self.prompt_manager.get_statistics()
            if stats['loaded_prompts'] > 0:
                self.use_prompt_manager = True
                self.supported_companies = list(self.prompt_manager.company_prompts.keys())
                logger.info(f"‚úÖ PromptManager loaded: {stats['loaded_prompts']} company prompts")
            else:
                logger.warning("‚ö†Ô∏è PromptManager: No company prompts loaded")
                
        except Exception as e:
            logger.error(f"‚ùå PromptManager initialization failed: {e}")
    
    # ========================================================================
    # üéØ MAIN PROCESSING METHOD - Enhanced Intent Detection
    # ========================================================================
    
    async def process_enhanced_question(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """üéØ Main processing method with enhanced intent detection"""
        
        if tenant_id not in self.tenant_configs:
            return self._create_error_response("Unknown tenant", tenant_id)
        
        start_time = datetime.now()
        self.stats['total_queries'] += 1
        
        try:
            # üÜï Enhanced Intent Detection
            intent_result = self.intent_detector.detect_intent(question)
            
            logger.info(f"üéØ Intent Detection Result for '{question[:50]}...': "
                       f"{intent_result['intent']} (confidence: {intent_result['confidence']:.2f})")
            
            # Log intent decision for analysis
            self._log_intent_decision(question, intent_result, tenant_id)
            
            # Route based on intent
            if intent_result['intent'] == 'conversational' and intent_result['confidence'] >= 0.6:
                return await self._process_conversational_question(question, tenant_id, start_time, intent_result)
            
            elif intent_result['intent'] == 'sql_query' and intent_result['confidence'] >= 0.5:
                return await self._process_sql_question(question, tenant_id, start_time, intent_result)
            
            else:
                # Ambiguous case - use hybrid approach
                return await self._process_hybrid_question(question, tenant_id, start_time, intent_result)
                
        except Exception as e:
            logger.error(f"‚ùå Processing failed for {tenant_id}: {e}")
            return self._create_error_response(str(e), tenant_id)
    
    async def _process_conversational_question(self, question: str, tenant_id: str, 
                                            start_time: datetime, intent_result: Dict) -> Dict[str, Any]:
        """üí¨ Process conversational questions (greetings, general info)"""
        
        self.stats['conversational_queries'] += 1
        
        try:
            # Use PromptManager if available and supported
            if self.use_prompt_manager and tenant_id in self.supported_companies:
                logger.info(f"üí¨ Using PromptManager for conversational query: {tenant_id}")
                result = await self.prompt_manager.process_query(question, tenant_id)
                
                processing_time = (datetime.now() - start_time).total_seconds()
                result.update({
                    'processing_time_seconds': processing_time,
                    'system_used': 'prompt_manager_conversational',
                    'intent_detection': intent_result,
                    'fixed_agent_version': 'v2.1_enhanced'
                })
                return result
            else:
                # Fallback conversational response
                return self._create_fallback_conversational_response(question, tenant_id, start_time, intent_result)
                
        except Exception as e:
            logger.error(f"‚ùå Conversational processing failed: {e}")
            return self._create_fallback_conversational_response(question, tenant_id, start_time, intent_result)
    
    async def _process_sql_question(self, question: str, tenant_id: str, 
                                  start_time: datetime, intent_result: Dict) -> Dict[str, Any]:
        """üéØ Process SQL questions with enhanced schema discovery"""
        
        self.stats['sql_queries'] += 1
        
        try:
            # üîç Get live schema information
            schema_info = await self.schema_inspector.get_live_schema_info(tenant_id)
            
            # üéØ Generate enhanced SQL prompt
            sql_prompt = await self._generate_enhanced_sql_prompt(question, tenant_id, schema_info, intent_result)
            
            # ü§ñ Call AI service to generate SQL
            config = self._get_config(tenant_id)
            ai_response = await self.ai_service.call_ollama_api(
                config, sql_prompt, temperature=0.1
            )
            
            # üîç Extract and validate SQL
            sql_query = self._extract_sql_with_validation(ai_response, question)
            
            if not self._is_valid_sql(sql_query):
                raise ValueError(f"Invalid or unsafe SQL generated: {sql_query}")
            
            # üóÑÔ∏è Execute SQL query
            results = await self._execute_sql_enhanced(sql_query, tenant_id)
            
            # üé® Format response with enhanced context
            formatted_answer = self._format_enhanced_response(
                results, question, tenant_id, schema_info, sql_query
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "answer": formatted_answer,
                "success": True,
                "data_source_used": f"enhanced_sql_{config.model_name}",
                "sql_query": sql_query,
                "db_results_count": len(results) if results else 0,
                "tenant_id": tenant_id,
                "processing_time_seconds": processing_time,
                "system_used": "enhanced_sql_with_schema_discovery",
                "intent_detection": intent_result,
                "schema_discovery": {
                    "used_live_schema": not schema_info.get('fallback', False),
                    "cache_hit": schema_info.get('discovered_at') != datetime.now().isoformat()
                },
                "fixed_agent_version": "v2.1_enhanced"
            }
            
        except Exception as e:
            logger.error(f"‚ùå SQL processing failed: {e}")
            return self._create_sql_error_response(question, tenant_id, str(e), intent_result)
    
    async def _process_hybrid_question(self, question: str, tenant_id: str, 
                                     start_time: datetime, intent_result: Dict) -> Dict[str, Any]:
        """üîÑ Process ambiguous questions using hybrid approach"""
        
        logger.info(f"üîÑ Using hybrid approach for ambiguous question: {question[:50]}...")
        
        # Try SQL first, fallback to conversational
        try:
            sql_result = await self._process_sql_question(question, tenant_id, start_time, intent_result)
            
            # If SQL returns meaningful results, use it
            if sql_result.get('success') and sql_result.get('db_results_count', 0) > 0:
                sql_result['system_used'] = 'hybrid_sql_successful'
                return sql_result
            else:
                # Fallback to conversational
                conv_result = await self._process_conversational_question(question, tenant_id, start_time, intent_result)
                conv_result['system_used'] = 'hybrid_conversational_fallback'
                return conv_result
                
        except Exception as e:
            # If SQL fails, try conversational
            logger.warning(f"Hybrid SQL failed, trying conversational: {e}")
            conv_result = await self._process_conversational_question(question, tenant_id, start_time, intent_result)
            conv_result['system_used'] = 'hybrid_conversational_after_sql_error'
            return conv_result
    
    # ========================================================================
    # üîß ENHANCED SQL GENERATION AND PROCESSING
    # ========================================================================
    
    async def _generate_enhanced_sql_prompt(self, question: str, tenant_id: str, 
                                          schema_info: Dict, intent_result: Dict) -> str:
        """üéØ Generate enhanced SQL prompt using real schema data"""
        
        config = self._get_config(tenant_id)
        business_context = self._get_business_context_enhanced(tenant_id)
        
        # Extract relevant tables based on question
        relevant_tables = self._identify_relevant_tables(question, schema_info)
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ PostgreSQL Expert ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {config.name}

{business_context}

üîç REAL DATABASE SCHEMA (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•):
"""
        
        # Add schema information for relevant tables
        for table_name in relevant_tables:
            if table_name in schema_info['tables']:
                table_info = schema_info['tables'][table_name]
                prompt += f"\nüìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á {table_name}:\n"
                
                for column in table_info['columns']:
                    prompt += f"  ‚Ä¢ {column['name']} ({column['type']})"
                    if not column['nullable']:
                        prompt += " [NOT NULL]"
                    prompt += "\n"
                
                # Add sample data if available
                if table_name in schema_info['sample_data']:
                    sample_data = schema_info['sample_data'][table_name]
                    if sample_data:
                        prompt += "  üìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á:\n"
                        for col, values in sample_data.items():
                            if values and len(values) > 0:
                                prompt += f"    {col}: {', '.join(map(str, values[:3]))}\n"
        
        # Add specific search rules based on intent
        search_guidance = self._get_search_guidance(question, intent_result)
        
        prompt += f"""
üéØ ‡∏Å‡∏é SQL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
{search_guidance}

üîß ‡∏Å‡∏é‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:
1. ‡πÉ‡∏ä‡πâ ILIKE '%keyword%' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏•‡πá‡∏Å)
2. ‡πÉ‡∏ä‡πâ COALESCE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ NULL values
3. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 20 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£: LIMIT 20
4. ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°

Intent Detection: {intent_result['intent']} (confidence: {intent_result['confidence']:.2f})
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏™‡∏£‡πâ‡∏≤‡∏á PostgreSQL query ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        return prompt
    
    def _identify_relevant_tables(self, question: str, schema_info: Dict) -> List[str]:
        """‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        
        question_lower = question.lower()
        relevant_tables = set()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏™‡∏°‡∏≠
        relevant_tables.add('employees')
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
        project_keywords = ['‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project', '‡∏á‡∏≤‡∏ô', '‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤', 'client']
        if any(keyword in question_lower for keyword in project_keywords):
            relevant_tables.add('projects')
            relevant_tables.add('employee_projects')
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        assignment_keywords = ['‡∏ó‡∏≥‡∏á‡∏≤‡∏ô', '‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö', 'assigned', 'working on']
        if any(keyword in question_lower for keyword in assignment_keywords):
            relevant_tables.add('employee_projects')
        
        return list(relevant_tables)
    
    def _get_search_guidance(self, question: str, intent_result: Dict) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        
        question_lower = question.lower()
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            position_keyword = self._extract_position_keyword(question)
            return f"""
1. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: position ILIKE '%{position_keyword}%'
2. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô: frontend = front-end = front end
3. ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: exact match ‡∏Å‡πà‡∏≠‡∏ô, partial match ‡∏ï‡∏≤‡∏°"""
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
        elif any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many']):
            return """
1. ‡πÉ‡∏ä‡πâ COUNT(*) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
2. ‡πÉ‡∏ä‡πâ GROUP BY ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°
3. ‡πÄ‡∏û‡∏¥‡πà‡∏° WHERE clause ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç"""
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ú‡∏ô‡∏Å
        elif '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower or 'department' in question_lower:
            return """
1. ‡πÉ‡∏ä‡πâ department ILIKE '%keyword%' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ú‡∏ô‡∏Å
2. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏ï‡πá‡∏°: IT = Information Technology
3. ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏ô"""
        
        # Default guidance
        else:
            return """
1. ‡πÉ‡∏ä‡πâ ILIKE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
2. ‡πÉ‡∏ä‡πâ JOIN ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á
3. ‡πÄ‡∏û‡∏¥‡πà‡∏° ORDER BY ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ú‡∏•"""
    
    def _extract_position_keyword(self, question: str) -> str:
        """‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        
        question_lower = question.lower()
        
        # Position patterns and their variations
        position_patterns = {
            'frontend': ['frontend', 'front-end', 'front end'],
            'backend': ['backend', 'back-end', 'back end'],
            'fullstack': ['fullstack', 'full-stack', 'full stack'],
            'developer': ['developer', 'dev', '‡∏û‡∏±‡∏í‡∏ô‡∏≤'],
            'designer': ['designer', 'design', '‡∏î‡∏µ‡πÑ‡∏ã‡∏ô‡πå'],
            'manager': ['manager', '‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£', '‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤'],
            'qa': ['qa', 'quality', '‡∏ó‡∏î‡∏™‡∏≠‡∏ö'],
            'devops': ['devops', 'dev-ops', 'ops']
        }
        
        for position, patterns in position_patterns.items():
            if any(pattern in question_lower for pattern in patterns):
                return position
        
        # If no specific pattern found, try to extract the word after "‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á"
        import re
        match = re.search(r'‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\s*(\w+)', question_lower)
        if match:
            return match.group(1)
        
        match = re.search(r'position\s*(\w+)', question_lower)
        if match:
            return match.group(1)
        
        return 'developer'  # default
    
    def _extract_sql_with_validation(self, ai_response: str, question: str) -> str:
        """üîç Extract SQL with enhanced validation"""
        
        # Try multiple patterns to extract SQL
        sql_patterns = [
            r'```sql\s*(.*?)\s*```',
            r'```\s*(SELECT.*?)\s*```',
            r'(SELECT.*?);?\s*(?:\n|$)',
            r'Query:\s*(SELECT.*?)(?:\n|$)'
        ]
        
        for pattern in sql_patterns:
            match = re.search(pattern, ai_response, re.DOTALL | re.IGNORECASE)
            if match:
                sql = match.group(1).strip()
                
                # Clean up the SQL
                sql = self._clean_sql(sql)
                
                # Validate that it makes sense for the question
                if self._validate_sql_relevance(sql, question):
                    return sql
        
        # If no valid SQL found, create a fallback
        logger.warning(f"No valid SQL extracted from AI response for question: {question}")
        return self._create_fallback_sql(question)
    
    def _clean_sql(self, sql: str) -> str:
        """üßπ Clean and normalize SQL query"""
        
        # Remove trailing semicolon
        sql = sql.rstrip(';').strip()
        
        # Remove extra whitespace
        sql = re.sub(r'\s+', ' ', sql)
        
        # Ensure proper SELECT format
        if not sql.upper().startswith('SELECT'):
            sql = f"SELECT {sql}" if not sql.startswith('*') else f"SELECT {sql}"
        
        return sql
    
    def _validate_sql_relevance(self, sql: str, question: str) -> bool:
        """üîç Validate that SQL is relevant to the question"""
        
        sql_lower = sql.lower()
        question_lower = question.lower()
        
        # Check for dangerous operations
        dangerous_ops = ['drop', 'delete', 'update', 'insert', 'alter', 'create', 'truncate']
        if any(op in sql_lower for op in dangerous_ops):
            return False
        
        # Check if SQL addresses the question intent
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            return 'position' in sql_lower
        
        if '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower or 'department' in question_lower:
            return 'department' in sql_lower
        
        if '‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô' in question_lower or 'how many' in question_lower:
            return 'count' in sql_lower
        
        # Basic check - must be a SELECT statement
        return sql_lower.startswith('select')
    
    def _create_fallback_sql(self, question: str) -> str:
        """üîÑ Create fallback SQL when extraction fails"""
        
        question_lower = question.lower()
        
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower and 'frontend' in question_lower:
            return """
            SELECT name, position, department, salary 
            FROM employees 
            WHERE position ILIKE '%frontend%' 
            ORDER BY name 
            LIMIT 20
            """
        
        elif '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower and '‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô' in question_lower:
            return """
            SELECT department, COUNT(*) as employee_count 
            FROM employees 
            GROUP BY department 
            ORDER BY employee_count DESC
            """
        
        else:
            return """
            SELECT name, department, position 
            FROM employees 
            ORDER BY name 
            LIMIT 20
            """
    
    async def _execute_sql_enhanced(self, sql_query: str, tenant_id: str) -> List[Dict[str, Any]]:
        """üéØ Enhanced SQL execution with better error handling"""
        
        try:
            logger.info(f"üóÑÔ∏è Executing SQL for {tenant_id}: {sql_query[:100]}...")
            
            results = self.database_handler.execute_sql_query(tenant_id, sql_query)
            
            # Convert Decimal to float for JSON serialization
            processed_results = []
            for row in results:
                processed_row = {}
                for key, value in row.items():
                    if isinstance(value, Decimal):
                        processed_row[key] = float(value)
                    else:
                        processed_row[key] = value
                processed_results.append(processed_row)
            
            logger.info(f"‚úÖ SQL executed successfully: {len(processed_results)} results")
            return processed_results
            
        except Exception as e:
            logger.error(f"‚ùå SQL execution failed for {tenant_id}: {e}")
            logger.error(f"‚ùå Failed SQL: {sql_query}")
            return []
    
    def _format_enhanced_response(self, results: List[Dict], question: str, 
                                tenant_id: str, schema_info: Dict, sql_query: str) -> str:
        """üé® Enhanced response formatting with business context"""
        
        if not results:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}"
        
        config = self._get_config(tenant_id)
        business_emoji = self._get_business_emoji(tenant_id)
        
        response = f"{business_emoji} ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ - {config.name}\n\n"
        response += f"üéØ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n\n"
        
        # Format results based on data type
        if self._is_counting_query(sql_query):
            response += self._format_counting_results(results, tenant_id)
        elif self._is_listing_query(sql_query):
            response += self._format_listing_results(results, tenant_id)
        else:
            response += self._format_general_results(results, tenant_id)
        
        # Add summary
        response += f"\nüí° ‡∏™‡∏£‡∏∏‡∏õ: ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
        
        # Add schema info if using live data
        if not schema_info.get('fallback', False):
            response += " (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)"
        
        return response
    
    def _is_counting_query(self, sql: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô query ‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        return 'count(' in sql.lower() or 'group by' in sql.lower()
    
    def _is_listing_query(self, sql: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô query ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        return 'name' in sql.lower() and 'count(' not in sql.lower()
    
    def _format_counting_results(self, results: List[Dict], tenant_id: str) -> str:
        """‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"""
        
        response = "üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô:\n"
        
        for i, row in enumerate(results, 1):
            response += f"{i:2d}. "
            
            for key, value in row.items():
                if 'count' in key.lower():
                    response += f"{key}: {value:,} ‡∏Ñ‡∏ô, "
                elif key.lower() == 'department':
                    response += f"‡πÅ‡∏ú‡∏ô‡∏Å{value}: "
                else:
                    response += f"{key}: {value}, "
            
            response = response.rstrip(', ') + "\n"
        
        return response
    
    def _format_listing_results(self, results: List[Dict], tenant_id: str) -> str:
        """‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"""
        
        response = "üë• ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô:\n"
        
        for i, row in enumerate(results[:15], 1):  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 15 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            response += f"{i:2d}. "
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô
            if 'name' in row:
                response += f"üë§ {row['name']}"
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
            if 'position' in row:
                response += f" - {row['position']}"
            
            # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏Å
            if 'department' in row:
                response += f" (‡πÅ‡∏ú‡∏ô‡∏Å{row['department']})"
            
            # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            if 'salary' in row and isinstance(row['salary'], (int, float)):
                currency = "USD" if tenant_id == 'company-c' else "‡∏ö‡∏≤‡∏ó"
                response += f" | ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {row['salary']:,.0f} {currency}"
            
            response += "\n"
        
        if len(results) > 15:
            response += f"... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(results) - 15} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n"
        
        return response
    
    def _format_general_results(self, results: List[Dict], tenant_id: str) -> str:
        """‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"""
        
        response = "üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏ö:\n"
        
        for i, row in enumerate(results[:10], 1):
            response += f"{i:2d}. "
            
            for key, value in row.items():
                if key.lower() in ['salary', 'budget'] and isinstance(value, (int, float)):
                    currency = "USD" if tenant_id == 'company-c' else "‡∏ö‡∏≤‡∏ó"
                    response += f"{key}: {value:,.0f} {currency}, "
                else:
                    response += f"{key}: {value}, "
            
            response = response.rstrip(', ') + "\n"
        
        if len(results) > 10:
            response += f"... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(results) - 10} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\n"
        
        return response
    
    # ========================================================================
    # üîß ENHANCED HELPER METHODS
    # ========================================================================
    
    def _get_business_context_enhanced(self, tenant_id: str) -> str:
        """üè¢ Enhanced business context with real data insights"""
        
        enhanced_contexts = {
            'company-a': """üè¢ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏ç‡πà ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏Ø - Enterprise Banking & E-commerce
üí∞ ‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô: ‡∏ö‡∏≤‡∏ó (THB)
üéØ ‡πÄ‡∏ô‡πâ‡∏ô: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£, CRM, ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (800K-3M ‡∏ö‡∏≤‡∏ó)
üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å: ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û, ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå, Central Group""",

            'company-b': """üè® ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: ‡∏™‡∏≤‡∏Ç‡∏≤‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà - Tourism & Hospitality Technology
üí∞ ‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô: ‡∏ö‡∏≤‡∏ó (THB)
üéØ ‡πÄ‡∏ô‡πâ‡∏ô: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°, ‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏•‡πâ‡∏≤‡∏ô‡∏ô‡∏≤ (300K-800K ‡∏ö‡∏≤‡∏ó)
üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å: ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡∏î‡∏∏‡∏™‡∏¥‡∏ï, ‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏´‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢""",

            'company-c': """üåç ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: International Office - Global Software Solutions
üí∞ ‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô: USD ‡πÅ‡∏•‡∏∞ Multi-currency
üéØ ‡πÄ‡∏ô‡πâ‡∏ô: ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®, Global compliance (1M-4M USD)
üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å: MegaCorp International (USA), Global Finance Corp (Singapore)"""
        }
        
        return enhanced_contexts.get(tenant_id, enhanced_contexts['company-a'])
    
    def _log_intent_decision(self, question: str, intent_result: Dict, tenant_id: str):
        """üìä Log intent decisions for analysis and improvement"""
        
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'question': question[:100],  # Truncate for privacy
            'intent': intent_result['intent'],
            'confidence': intent_result['confidence'],
            'sql_score': intent_result.get('sql_score', 0),
            'conv_score': intent_result.get('conv_score', 0),
            'tenant_id': tenant_id
        }
        
        try:
            # Append to intent log file
            import os
            os.makedirs('/app/logs', exist_ok=True)
            with open('/app/logs/intent_decisions.jsonl', 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.warning(f"Could not log intent decision: {e}")
    
    # ========================================================================
    # üîÑ FALLBACK AND ERROR HANDLING
    # ========================================================================
    
    def _create_fallback_conversational_response(self, question: str, tenant_id: str, 
                                               start_time: datetime, intent_result: Dict) -> Dict[str, Any]:
        """üí¨ Create fallback conversational response"""
        
        config = self._get_config(tenant_id)
        business_emoji = self._get_business_emoji(tenant_id)
        processing_time = (datetime.now() - start_time).total_seconds()
        
        if self._is_greeting(question):
            fallback_greetings = {
                'company-a': f"""‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ AI Assistant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {config.name} (Enhanced v2.1)

{business_emoji} ‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: 
  ‚Ä¢ "‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á frontend ‡∏ö‡πâ‡∏≤‡∏á"
  ‚Ä¢ "‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å IT"
  ‚Ä¢ "‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏°‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£" """,

                'company-b': f"""‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡πÄ‡∏à‡πâ‡∏≤! ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ AI Assistant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {config.name} (Enhanced v2.1)

{business_emoji} ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏•‡∏∞‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏° - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£
üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: 
  ‚Ä¢ "‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á designer ‡∏ö‡πâ‡∏≤‡∏á"
  ‚Ä¢ "‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á"
  ‚Ä¢ "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡πÉ‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà" """,

                'company-c': f"""Hello! I'm the AI Assistant for {config.name} (Enhanced v2.1)

{business_emoji} International Operations - Ready to help
üí° Example questions: 
  ‚Ä¢ "Who are the frontend developers?"
  ‚Ä¢ "How many employees in each department?"
  ‚Ä¢ "What's the USD budget breakdown?" """
            }
            
            answer = fallback_greetings.get(tenant_id, fallback_greetings['company-a'])
        else:
            answer = f"{business_emoji} Enhanced System ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {config.name}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n\nüí° ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô:\n‚Ä¢ ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô: \"‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á [‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á] ‡∏ö‡πâ‡∏≤‡∏á\"\n‚Ä¢ ‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: \"‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å [‡πÅ‡∏ú‡∏ô‡∏Å]\""
        
        return {
            "answer": answer,
            "success": True,
            "data_source_used": f"enhanced_conversational_{config.model_name}",
            "sql_query": None,
            "tenant_id": tenant_id,
            "processing_time_seconds": processing_time,
            "system_used": "enhanced_conversational_fallback",
            "intent_detection": intent_result,
            "fixed_agent_version": "v2.1_enhanced"
        }
    
    def _create_sql_error_response(self, question: str, tenant_id: str, 
                                 error_message: str, intent_result: Dict) -> Dict[str, Any]:
        """‚ùå Create SQL error response with helpful guidance"""
        
        config = self._get_config(tenant_id)
        business_emoji = self._get_business_emoji(tenant_id)
        
        answer = f"""{business_emoji} ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {error_message}

üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
‚Ä¢ ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
‚Ä¢ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á frontend ‡∏ö‡πâ‡∏≤‡∏á" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏°‡∏µ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏Å IT"

‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"""
        
        return {
            "answer": answer,
            "success": False,
            "data_source_used": f"enhanced_sql_error_{config.model_name}",
            "sql_query": None,
            "tenant_id": tenant_id,
            "system_used": "enhanced_sql_error_handling",
            "intent_detection": intent_result,
            "error_reason": error_message,
            "fixed_agent_version": "v2.1_enhanced"
        }
    
    def _create_error_response(self, error_message: str, tenant_id: str) -> Dict[str, Any]:
        """‚ùå Create general error response"""
        return {
            "answer": f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {error_message}",
            "success": False,
            "data_source_used": "enhanced_error",
            "sql_query": None,
            "tenant_id": tenant_id,
            "system_used": "error_handler",
            "error": error_message,
            "fixed_agent_version": "v2.1_enhanced"
        }
    
    # ========================================================================
    # üîß UTILITY METHODS (Enhanced versions)
    # ========================================================================
    
    def _is_greeting(self, question: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        greetings = ['‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ', 'hello', 'hi', '‡∏ä‡πà‡∏ß‡∏¢', 'help', '‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£']
        return any(word in question.lower() for word in greetings)
    
    def _is_valid_sql(self, sql: str) -> bool:
        """üîí Enhanced SQL validation for security"""
        if not sql or not sql.strip():
            return False
        
        sql_upper = sql.upper()
        dangerous_keywords = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'CREATE', 'TRUNCATE']
        
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                logger.warning(f"üö® Dangerous SQL keyword detected: {keyword}")
                return False
        
        # Must start with SELECT
        if not sql_upper.strip().startswith('SELECT'):
            return False
        
        # Basic syntax check
        if sql_upper.count('SELECT') > 5:  # Prevent overly complex queries
            logger.warning("üö® Query too complex")
            return False
        
        return True
    
    def _get_config(self, tenant_id: str) -> TenantConfig:
        """üìù Get tenant configuration"""
        return self.tenant_configs[tenant_id]
    
    def _get_business_emoji(self, tenant_id: str) -> str:
        """üéØ Get business emoji for each company"""
        emojis = {
            'company-a': 'üè¶',  # Banking
            'company-b': 'üè®',  # Tourism  
            'company-c': 'üåç'   # International
        }
        return emojis.get(tenant_id, 'üíº')
    
    # ========================================================================
    # üìä SYSTEM MONITORING AND STATISTICS
    # ========================================================================
    
    def get_enhanced_statistics(self) -> Dict[str, Any]:
        """üìä Get comprehensive system statistics"""
        
        success_rate = 0
        if self.stats['total_queries'] > 0:
            success_rate = ((self.stats['sql_queries'] + self.stats['conversational_queries']) / 
                          self.stats['total_queries']) * 100
        
        return {
            'agent_version': 'enhanced_v2.1_with_intent_detection',
            'total_queries': self.stats['total_queries'],
            'sql_queries': self.stats['sql_queries'],
            'conversational_queries': self.stats['conversational_queries'],
            'success_rate': round(success_rate, 2),
            'intent_detection': {
                'enabled': True,
                'version': 'enhanced_multi_pattern_v2.1'
            },
            'schema_discovery': {
                'enabled': True,
                'cache_enabled': True,
                'cache_ttl': self.schema_inspector.cache_ttl
            },
            'prompt_manager': {
                'available': PROMPT_MANAGER_AVAILABLE,
                'active': self.use_prompt_manager,
                'supported_companies': getattr(self, 'supported_companies', [])
            },
            'tenant_configs': list(self.tenant_configs.keys()),
            'enhanced_features': [
                'real_time_schema_discovery',
                'enhanced_intent_detection',
                'adaptive_sql_generation',
                'business_context_awareness',
                'error_recovery_mechanisms'
            ]
        }
    
    # ========================================================================
    # üîÑ COMPATIBILITY METHODS
    # ========================================================================
    
    async def process_question(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """Compatibility method"""
        return await self.process_enhanced_question(question, tenant_id)
    
    async def process_enhanced_question_streaming(self, question: str, tenant_id: str):
        """Enhanced streaming implementation"""
        
        # Send initial status
        yield {
            "type": "status", 
            "message": "üéØ Enhanced Intent Detection...", 
            "system": "enhanced_v2.1"
        }
        
        # Detect intent
        intent_result = self.intent_detector.detect_intent(question)
        yield {
            "type": "intent_detected",
            "intent": intent_result['intent'],
            "confidence": intent_result['confidence'],
            "message": f"Intent: {intent_result['intent']} (confidence: {intent_result['confidence']:.2f})"
        }
        
        # Process question
        result = await self.process_enhanced_question(question, tenant_id)
        
        # Stream answer in chunks
        answer = result["answer"]
        chunk_size = 100
        
        for i in range(0, len(answer), chunk_size):
            chunk = answer[i:i+chunk_size]
            yield {"type": "answer_chunk", "content": chunk}
            
        # Send completion info
        yield {
            "type": "answer_complete",
            "sql_query": result.get("sql_query"),
            "db_results_count": result.get("db_results_count", 0),
            "processing_time_seconds": result.get("processing_time_seconds", 0),
            "tenant_id": tenant_id,
            "system_used": result.get("system_used", "enhanced_v2.1"),
            "intent_detection": result.get("intent_detection", {}),
            "fixed_agent_version": "v2.1_enhanced"
        }