# refactored_modules/ai_service.py
# ü§ñ Enhanced AI/Ollama Communication Service with Smart Prompt Engineering

import os
import json
import asyncio
import aiohttp
import re
import time
from typing import AsyncGenerator, Dict, Any, List, Optional, Tuple
import logging
from datetime import datetime, timedelta
from .tenant_config import TenantConfig  # ‚úÖ Only import TenantConfig, not AIService

logger = logging.getLogger(__name__)

class EnhancedAIService:
    """ü§ñ Enhanced AI Service with smart prompt engineering and response optimization"""
    
    def __init__(self):
        self.ollama_base_url = os.getenv('OLLAMA_BASE_URL', 'http://52.74.36.160:12434')
        self.request_timeout = int(os.getenv('AI_REQUEST_TIMEOUT', '90'))
        self.max_retries = int(os.getenv('AI_MAX_RETRIES', '3'))
        
        # Performance tracking
        self.performance_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'avg_response_time': 0,
            'cache_hits': 0,
            'tenant_breakdown': {}
        }
        
        # Response cache for identical prompts
        self.response_cache = {}
        self.cache_ttl = 300  # 5 minutes
        
        # Model-specific configurations
        self.model_configs = {
            'llama3.1:8b': {
                'temperature': 0.1,
                'num_predict': 800,
                'top_k': 20,
                'top_p': 0.8,
                'repeat_penalty': 1.0,
                'num_ctx': 2048
            },
            'gemma2:9b': {
                'temperature': 0.2,
                'num_predict': 1000,
                'top_k': 25,
                'top_p': 0.85,
                'repeat_penalty': 1.05,
                'num_ctx': 2048
            },
            'phi3:14b': {
                'temperature': 0.15,
                'num_predict': 1200,
                'top_k': 30,
                'top_p': 0.9,
                'repeat_penalty': 1.02,
                'num_ctx': 4096
            }
        }
        
        logger.info("‚úÖ Enhanced AI Service initialized")
        logger.info(f"üåê Ollama URL: {self.ollama_base_url}")
        logger.info(f"‚è±Ô∏è Timeout: {self.request_timeout}s")
    
    # ========================================================================
    # üéØ ENHANCED PROMPT ENGINEERING
    # ========================================================================
    
    async def generate_enhanced_sql_prompt(self, question: str, tenant_config: TenantConfig, 
                                         schema_info: Dict, intent_result: Dict) -> str:
        """üéØ Generate SIMPLE and WORKING SQL prompt"""
        
        # Get business-specific context
        business_context = self._get_business_context(tenant_config)
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ PostgreSQL Expert ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {tenant_config.name}

{business_context}

üìä ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
‚Ä¢ employees: id, name, department, position, salary, hire_date, email
‚Ä¢ projects: id, name, client, budget, status, start_date, end_date, tech_stack
‚Ä¢ employee_projects: employee_id, project_id, role, allocation

üìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á:
‚Ä¢ department: {', '.join(schema_info.get('sample_data', {}).get('employees', {}).get('department', ['IT', 'Sales']))}
‚Ä¢ position: {', '.join(schema_info.get('sample_data', {}).get('employees', {}).get('position', ['Developer', 'Designer'])[:5])}

üîß ‡∏Å‡∏é SQL ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏´‡πâ‡∏≤‡∏°‡∏ú‡∏¥‡∏î):
1. ‡πÉ‡∏ä‡πâ ILIKE '%keyword%' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏•‡πá‡∏Å)
2. ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ COALESCE ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
3. ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô SQL ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
4. ‡πÉ‡∏ä‡πâ LIMIT 20 ‡πÄ‡∏™‡∏°‡∏≠
5. ‡πÉ‡∏ä‡πâ ORDER BY ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢

üéØ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

üìö ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á SQL ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á:

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 1 - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á:
```sql
SELECT name, position, department 
FROM employees 
WHERE position ILIKE '%frontend%' 
ORDER BY name 
LIMIT 20;
```

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 2 - ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô‡∏Å:
```sql
SELECT department, COUNT(*) as employee_count 
FROM employees 
GROUP BY department 
ORDER BY employee_count DESC;
```

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 3 - ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:
```sql
SELECT name, position, department 
FROM employees 
ORDER BY name 
LIMIT 20;
```

‡∏™‡∏£‡πâ‡∏≤‡∏á PostgreSQL query ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ:"""
        
        return prompt
    
    def _get_business_context(self, tenant_config: TenantConfig) -> str:
        """üè¢ Get business-specific context for better AI understanding"""
        
        contexts = {
            'enterprise_software': """üè¢ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: Enterprise Software Development
üí∞ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: 800,000 - 3,000,000+ ‡∏ö‡∏≤‡∏ó
üéØ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£, ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÉ‡∏´‡∏ç‡πà, E-commerce
üìä ‡πÇ‡∏ü‡∏Å‡∏±‡∏™: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£, CRM, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£""",

            'tourism_hospitality': """üè® ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: Tourism & Hospitality Technology
üí∞ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: 300,000 - 800,000 ‡∏ö‡∏≤‡∏ó
üéØ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°, ‡∏£‡∏µ‡∏™‡∏≠‡∏£‡πå‡∏ó, ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß
üìä ‡πÇ‡∏ü‡∏Å‡∏±‡∏™: ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≠‡∏á‡∏´‡πâ‡∏≠‡∏á, ‡πÅ‡∏≠‡∏õ‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£""",

            'global_operations': """üåç ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: Global Software Solutions
üí∞ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: 1,000,000 - 4,000,000+ USD
üéØ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏≤‡∏ï‡∏¥, ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
üìä ‡πÇ‡∏ü‡∏Å‡∏±‡∏™: ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®, Multi-currency, Global compliance"""
        }
        
        return contexts.get(tenant_config.business_type, contexts['enterprise_software'])
    
    def _extract_query_hints(self, question: str, intent_result: Dict, schema_info: Dict) -> str:
        """üîç Extract specific hints for the query type"""
        
        question_lower = question.lower()
        hints = ["üîß ‡∏Å‡∏é SQL ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ:"]
        
        # Position search hints
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            position_keyword = self._extract_keyword(question, ['frontend', 'backend', 'developer', 'designer'])
            hints.extend([
                f"1. ‡πÉ‡∏ä‡πâ position ILIKE '%{position_keyword}%' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á",
                "2. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô: frontend = front-end = front end",
                "3. ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: exact match ‡∏Å‡πà‡∏≠‡∏ô"
            ])
        
        # Department counting hints
        elif any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many']):
            if '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower:
                hints.extend([
                    "1. ‡πÉ‡∏ä‡πâ COUNT(*) ‡∏Å‡∏±‡∏ö GROUP BY department",
                    "2. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô‡∏Å‡πÄ‡∏ï‡πá‡∏°: IT = Information Technology",
                    "3. ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏ô: ORDER BY COUNT(*) DESC"
                ])
            else:
                hints.extend([
                    "1. ‡πÉ‡∏ä‡πâ COUNT(*) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°",
                    "2. ‡πÄ‡∏û‡∏¥‡πà‡∏° WHERE clause ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î",
                    "3. ‡πÉ‡∏ä‡πâ DISTINCT ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥"
                ])
        
        # Listing hints
        elif any(word in question_lower for word in ['‡πÉ‡∏Ñ‡∏£‡∏ö‡πâ‡∏≤‡∏á', '‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠', 'who are']):
            hints.extend([
                "1. SELECT name, position, department ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô",
                "2. ‡πÄ‡∏û‡∏¥‡πà‡∏° salary ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö",
                "3. ‡πÉ‡∏ä‡πâ ORDER BY name ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö"
            ])
        
        # Add sample data hints if available
        if 'sample_data' in schema_info and schema_info['sample_data']:
            hints.append("\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á:")
            for table, data in schema_info['sample_data'].items():
                if data and table == 'employees':  # Focus on employees table
                    for column, values in data.items():
                        if values and len(values) > 0:
                            hints.append(f"   {column}: {', '.join(map(str, values[:3]))}")
        
        return '\n'.join(hints)
    
    def _build_schema_section(self, schema_info: Dict, question: str) -> str:
        """üóÑÔ∏è Build comprehensive schema section based on question relevance"""
        
        if not schema_info or 'tables' not in schema_info:
            return "üìä ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"
        
        # Determine relevant tables based on question
        relevant_tables = self._identify_relevant_tables(question, schema_info)
        
        schema_section = "üìä ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á):\n"
        
        for table_name in relevant_tables:
            if table_name in schema_info['tables']:
                table_info = schema_info['tables'][table_name]
                schema_section += f"\nüîπ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á {table_name}:\n"
                
                # Add columns with enhanced info
                for column in table_info['columns'][:10]:  # Limit to prevent prompt overflow
                    nullable_info = "" if column.get('nullable', True) else " [NOT NULL]"
                    type_info = column.get('type', 'unknown')
                    schema_section += f"   ‚Ä¢ {column['name']} ({type_info}){nullable_info}\n"
                
                # Add foreign key relationships
                if 'foreign_keys' in table_info and table_info['foreign_keys']:
                    schema_section += "   üîó ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå:\n"
                    for fk in table_info['foreign_keys'][:3]:  # Limit to 3
                        schema_section += f"     - {fk['column']} ‚Üí {fk['references_table']}.{fk['references_column']}\n"
        
        # Add business insights if available
        if 'business_insights' in schema_info and schema_info['business_insights']:
            insights = schema_info['business_insights']
            if 'department_info' in insights and insights['department_info']:
                dept_info = insights['department_info']
                schema_section += f"\nüí° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å: ‡∏°‡∏µ {dept_info.get('total_departments', 0)} ‡πÅ‡∏ú‡∏ô‡∏Å"
                if 'largest_department' in dept_info:
                    schema_section += f", ‡πÅ‡∏ú‡∏ô‡∏Å‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î: {dept_info['largest_department']}"
        
        return schema_section
    
    def _identify_relevant_tables(self, question: str, schema_info: Dict) -> List[str]:
        """‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        
        question_lower = question.lower()
        relevant_tables = ['employees']  # Always include employees as primary table
        
        # Check for project-related keywords
        project_keywords = ['‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project', '‡∏á‡∏≤‡∏ô', '‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤', 'client']
        if any(keyword in question_lower for keyword in project_keywords):
            relevant_tables.extend(['projects', 'employee_projects'])
        
        # Check for department-related keywords (if departments table exists)
        if 'departments' in schema_info.get('tables', {}):
            dept_keywords = ['‡πÅ‡∏ú‡∏ô‡∏Å', 'department', '‡∏ù‡πà‡∏≤‡∏¢']
            if any(keyword in question_lower for keyword in dept_keywords):
                relevant_tables.append('departments')
        
        # Check for client-related keywords
        if 'clients' in schema_info.get('tables', {}):
            client_keywords = ['‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤', 'client', 'customer']
            if any(keyword in question_lower for keyword in client_keywords):
                relevant_tables.append('clients')
        
        return list(set(relevant_tables))  # Remove duplicates
    
    def _generate_relevant_examples(self, question: str, tenant_config: TenantConfig, intent_result: Dict) -> str:
        """üìö Generate relevant SQL examples based on query type"""
        
        question_lower = question.lower()
        examples = ["üìö ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á SQL ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:"]
        
        # Position search examples
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            examples.extend([
                "",
                "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 1 - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞:",
                "```sql",
                "SELECT name, position, department, salary",
                "FROM employees",
                "WHERE position ILIKE '%frontend%'",
                "ORDER BY name",
                "LIMIT 20;",
                "```"
            ])
        
        # Counting examples
        elif any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many']):
            examples.extend([
                "",
                "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 1 - ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô‡∏Å:",
                "```sql",
                "SELECT department, COUNT(*) as employee_count",
                "FROM employees",
                "GROUP BY department",
                "ORDER BY employee_count DESC;",
                "```"
            ])
        
        # Listing examples
        elif any(word in question_lower for word in ['‡πÉ‡∏Ñ‡∏£‡∏ö‡πâ‡∏≤‡∏á', '‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠', 'who are']):
            examples.extend([
                "",
                "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 1 - ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô:",
                "```sql",
                "SELECT name, position, department",
                "FROM employees",
                "WHERE department ILIKE '%IT%'",
                "ORDER BY name",
                "LIMIT 20;",
                "```"
            ])
        
        return '\n'.join(examples)
    
    def _extract_keyword(self, text: str, keywords: List[str]) -> str:
        """Extract specific keyword from text"""
        text_lower = text.lower()
        for keyword in keywords:
            if keyword in text_lower:
                return keyword
        return keywords[0] if keywords else 'developer'
    
    # ========================================================================
    # ü§ñ ENHANCED OLLAMA API CALLS
    # ========================================================================
    
    async def call_ollama_api(self, tenant_config: TenantConfig, prompt: str, 
                             context_data: str = "", temperature: float = None) -> str:
        """Enhanced Ollama API call with intelligent model configuration"""
        
        start_time = time.time()
        
        try:
            # Get model-specific configuration
            model_config = self.model_configs.get(tenant_config.model_name, self.model_configs['llama3.1:8b'])
            
            # Override temperature if provided
            if temperature is not None:
                model_config = model_config.copy()
                model_config['temperature'] = temperature
            
            # Prepare full prompt
            full_prompt = self._prepare_full_prompt(prompt, context_data, tenant_config)
            
            # Check cache first
            cache_key = self._generate_cache_key(full_prompt, tenant_config.model_name)
            cached_response = self._get_cached_response(cache_key)
            if cached_response:
                self._update_performance_stats(tenant_config.tenant_id, time.time() - start_time, True, True)
                return cached_response
            
            # Prepare request payload
            payload = {
                "model": tenant_config.model_name,
                "prompt": full_prompt,
                "stream": False,
                "options": model_config
            }
            
            # Make API call with retry logic
            response_text = await self._make_api_call_with_retry(payload, tenant_config)
            
            # Cache successful response
            self._cache_response(cache_key, response_text)
            
            # Update performance stats
            execution_time = time.time() - start_time
            self._update_performance_stats(tenant_config.tenant_id, execution_time, True, False)
            
            return response_text
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_performance_stats(tenant_config.tenant_id, execution_time, False, False)
            logger.error(f"‚ùå Enhanced Ollama API call failed for {tenant_config.tenant_id}: {e}")
            return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI: {str(e)}"
    
    def _prepare_full_prompt(self, prompt: str, context_data: str, tenant_config: TenantConfig) -> str:
        """Prepare optimized full prompt"""
        
        # Add system context based on tenant
        system_context = f"System: You are an expert AI assistant for {tenant_config.name} ({tenant_config.business_type})"
        
        if context_data:
            full_prompt = f"{system_context}\n\n{prompt}\n\nContext Data:\n{context_data}\n\nAssistant:"
        else:
            full_prompt = f"{system_context}\n\n{prompt}\n\nAssistant:"
        
        return full_prompt
    
    async def _make_api_call_with_retry(self, payload: Dict, tenant_config: TenantConfig) -> str:
        """Make API call with intelligent retry logic"""
        
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"ü§ñ AI API call attempt {attempt + 1} for {tenant_config.tenant_id}")
                
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        f"{self.ollama_base_url}/api/generate",
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=self.request_timeout)
                    ) as response:
                        
                        if response.status == 200:
                            result = await response.json()
                            response_text = result.get('response', '')
                            
                            if response_text.strip():
                                logger.info(f"‚úÖ AI API call successful for {tenant_config.tenant_id}")
                                return response_text
                            else:
                                raise ValueError("Empty response from AI")
                        else:
                            raise aiohttp.ClientResponseError(
                                request_info=response.request_info,
                                history=response.history,
                                status=response.status,
                                message=f"HTTP {response.status}"
                            )
                            
            except asyncio.TimeoutError as e:
                last_error = f"Timeout after {self.request_timeout}s (attempt {attempt + 1})"
                logger.warning(f"‚è∞ {last_error}")
                
                # Increase timeout for next attempt
                if attempt < self.max_retries - 1:
                    self.request_timeout = min(self.request_timeout + 30, 120)
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
                    
            except Exception as e:
                last_error = f"API call error: {str(e)} (attempt {attempt + 1})"
                logger.warning(f"üîÑ {last_error}")
                
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
        
        raise Exception(f"All {self.max_retries} attempts failed. Last error: {last_error}")
    
    # ========================================================================
    # üîÑ STREAMING SUPPORT
    # ========================================================================
    
    async def call_ollama_api_streaming(self, tenant_config: TenantConfig, prompt: str, 
                                       context_data: str = "", temperature: float = None) -> AsyncGenerator:
        """Enhanced streaming version with better chunk processing"""
        
        try:
            # Get model configuration
            model_config = self.model_configs.get(tenant_config.model_name, self.model_configs['llama3.1:8b'])
            if temperature is not None:
                model_config = model_config.copy()
                model_config['temperature'] = temperature
            
            # Prepare full prompt
            full_prompt = self._prepare_full_prompt(prompt, context_data, tenant_config)
            
            # Prepare streaming payload
            payload = {
                "model": tenant_config.model_name,
                "prompt": full_prompt,
                "stream": True,
                "options": model_config
            }
            
            logger.info(f"üåä Starting streaming AI call for {tenant_config.tenant_id}")
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.ollama_base_url}/api/generate",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.request_timeout * 2)  # Longer timeout for streaming
                ) as response:
                    
                    if response.status == 200:
                        accumulated_response = ""
                        
                        async for line in response.content:
                            if line:
                                try:
                                    line_text = line.decode('utf-8').strip()
                                    if line_text:
                                        data = json.loads(line_text)
                                        
                                        if 'response' in data and data['response']:
                                            chunk = data['response']
                                            accumulated_response += chunk
                                            yield chunk
                                        
                                        # Check if streaming is complete
                                        if data.get('done', False):
                                            logger.info(f"‚úÖ Streaming completed for {tenant_config.tenant_id}")
                                            break
                                            
                                except json.JSONDecodeError:
                                    continue  # Skip invalid JSON lines
                    else:
                        error_msg = f"HTTP {response.status} error from AI service"
                        logger.error(f"‚ùå {error_msg}")
                        yield error_msg
                        
        except asyncio.TimeoutError:
            error_msg = f"AI streaming timeout after {self.request_timeout * 2}s"
            logger.error(f"‚è∞ {error_msg}")
            yield error_msg
        except Exception as e:
            error_msg = f"Streaming error: {str(e)}"
            logger.error(f"‚ùå {error_msg}")
            yield error_msg
    
    # ========================================================================
    # üß† INTELLIGENT RESPONSE PROCESSING
    # ========================================================================
    
    def extract_sql_with_validation(self, ai_response: str, question: str, 
                                   tenant_config: TenantConfig) -> Dict[str, Any]:
        """Enhanced SQL extraction with validation and confidence scoring"""
        
        extraction_result = {
            'sql': None,
            'confidence': 0.0,
            'extraction_method': None,
            'validation_issues': [],
            'suggestions': []
        }
        
        # Try multiple extraction methods
        extraction_methods = [
            ('code_block_sql', self._extract_from_sql_code_block),
            ('code_block_generic', self._extract_from_code_block),
            ('select_pattern', self._extract_from_select_pattern),
            ('fallback_generation', self._generate_fallback_sql)
        ]
        
        for method_name, method_func in extraction_methods:
            try:
                sql = method_func(ai_response, question)
                if sql and self._basic_sql_validation(sql):
                    
                    # Calculate confidence based on method and SQL quality
                    confidence = self._calculate_sql_confidence(sql, question, method_name)
                    
                    if confidence > extraction_result['confidence']:
                        extraction_result.update({
                            'sql': sql,
                            'confidence': confidence,
                            'extraction_method': method_name
                        })
                        
                        # Stop if we have high confidence
                        if confidence >= 0.8:
                            break
                            
            except Exception as e:
                logger.warning(f"SQL extraction method {method_name} failed: {e}")
                continue
        
        # Validate final SQL
        if extraction_result['sql']:
            validation_issues = self._validate_sql_relevance(extraction_result['sql'], question)
            extraction_result['validation_issues'] = validation_issues
            
            # Adjust confidence based on validation issues
            if validation_issues:
                extraction_result['confidence'] *= 0.7  # Reduce confidence if issues found
        
        return extraction_result
    
    def _extract_from_sql_code_block(self, response: str, question: str) -> Optional[str]:
        """Extract SQL from ```sql code blocks"""
        pattern = r'```sql\s*(.*?)\s*```'
        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
        return self._clean_sql(match.group(1)) if match else None
    
    def _extract_from_code_block(self, response: str, question: str) -> Optional[str]:
        """Extract SQL from generic ``` code blocks"""
        pattern = r'```\s*(SELECT.*?)\s*```'
        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
        return self._clean_sql(match.group(1)) if match else None
    
    def _extract_from_select_pattern(self, response: str, question: str) -> Optional[str]:
        """Extract SQL using SELECT pattern matching"""
        pattern = r'(SELECT\s+.+?)(?:\n\s*\n|$)'
        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
        return self._clean_sql(match.group(1)) if match else None
    
    def _generate_fallback_sql(self, response: str, question: str) -> Optional[str]:
        """Generate SIMPLE fallback SQL when extraction fails"""
        
        question_lower = question.lower()
        
        # Position search fallback - SIMPLIFIED
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            if 'frontend' in question_lower:
                return "SELECT name, position, department FROM employees WHERE position ILIKE '%frontend%' ORDER BY name LIMIT 20"
            elif 'backend' in question_lower:
                return "SELECT name, position, department FROM employees WHERE position ILIKE '%backend%' ORDER BY name LIMIT 20"
            elif 'designer' in question_lower:
                return "SELECT name, position, department FROM employees WHERE position ILIKE '%designer%' ORDER BY name LIMIT 20"
            elif 'developer' in question_lower:
                return "SELECT name, position, department FROM employees WHERE position ILIKE '%developer%' ORDER BY name LIMIT 20"
            else:
                return "SELECT name, position, department FROM employees WHERE position ILIKE '%developer%' ORDER BY name LIMIT 20"
        
        # Department counting fallback - SIMPLIFIED
        elif '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower and any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many']):
            if 'it' in question_lower:
                return "SELECT COUNT(*) as employee_count FROM employees WHERE department ILIKE '%IT%'"
            else:
                return "SELECT department, COUNT(*) as employee_count FROM employees GROUP BY department ORDER BY employee_count DESC"
        
        # General employee listing - SIMPLIFIED
        elif any(word in question_lower for word in ['‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô', 'employee', '‡πÉ‡∏Ñ‡∏£‡∏ö‡πâ‡∏≤‡∏á']):
            return "SELECT name, position, department FROM employees ORDER BY name LIMIT 20"
        
        # Project listing
        elif any(word in question_lower for word in ['‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ', 'project']):
            return "SELECT name, client, budget, status FROM projects ORDER BY name LIMIT 20"
        
        return None
    
    def _clean_sql(self, sql: str) -> str:
        """Clean and normalize SQL query"""
        if not sql:
            return ""
        
        # Remove trailing semicolon and whitespace
        sql = sql.rstrip(';').strip()
        
        # Replace multiple whitespace with single space
        sql = re.sub(r'\s+', ' ', sql)
        
        # Ensure proper capitalization for keywords
        keywords = ['SELECT', 'FROM', 'WHERE', 'ORDER BY', 'GROUP BY', 'HAVING', 'LIMIT']
        for keyword in keywords:
            sql = re.sub(rf'\b{keyword.lower()}\b', keyword, sql, flags=re.IGNORECASE)
        
        return sql
    
    def _basic_sql_validation(self, sql: str) -> bool:
        """Basic SQL validation"""
        if not sql or not sql.strip():
            return False
        
        sql_upper = sql.upper().strip()
        
        # Must start with SELECT
        if not sql_upper.startswith('SELECT'):
            return False
        
        # Check for dangerous keywords
        dangerous_keywords = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'CREATE', 'TRUNCATE']
        return not any(keyword in sql_upper for keyword in dangerous_keywords)
    
    def _calculate_sql_confidence(self, sql: str, question: str, method: str) -> float:
        """Calculate confidence score for extracted SQL"""
        
        confidence = 0.0
        
        # Base confidence by extraction method
        method_confidence = {
            'code_block_sql': 0.9,
            'code_block_generic': 0.8,
            'select_pattern': 0.7,
            'fallback_generation': 0.5
        }
        confidence += method_confidence.get(method, 0.3)
        
        # Boost confidence if SQL contains relevant keywords from question
        question_lower = question.lower()
        sql_lower = sql.lower()
        
        keyword_matches = 0
        total_keywords = 0
        
        # Check for position keywords
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower or 'position' in question_lower:
            total_keywords += 1
            if 'position' in sql_lower:
                keyword_matches += 1
        
        # Check for department keywords
        if '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower or 'department' in question_lower:
            total_keywords += 1
            if 'department' in sql_lower:
                keyword_matches += 1
        
        # Check for counting keywords
        if any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'how many']):
            total_keywords += 1
            if 'count' in sql_lower:
                keyword_matches += 1
        
        # Adjust confidence based on keyword matching
        if total_keywords > 0:
            keyword_ratio = keyword_matches / total_keywords
            confidence *= (0.5 + 0.5 * keyword_ratio)  # Scale between 0.5 and 1.0
        
        # Check SQL complexity appropriateness
        if 'LIMIT' in sql.upper():
            confidence += 0.1  # Good practice
        
        if len(sql) > 20 and len(sql) < 200:
            confidence += 0.05  # Reasonable length
        
        return min(confidence, 1.0)  # Cap at 1.0
    
    def _validate_sql_relevance(self, sql: str, question: str) -> List[str]:
        """Validate SQL relevance to question and return issues"""
        
        issues = []
        sql_lower = sql.lower()
        question_lower = question.lower()
        
        # Check if SQL addresses question intent
        if '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á' in question_lower and 'position' not in sql_lower:
            issues.append("SQL doesn't search by position as requested")
        
        if '‡πÅ‡∏ú‡∏ô‡∏Å' in question_lower and 'department' not in sql_lower:
            issues.append("SQL doesn't filter by department as requested")
        
        if any(word in question_lower for word in ['‡∏Å‡∏µ‡πà‡∏Ñ‡∏ô', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô']) and 'count' not in sql_lower:
            issues.append("SQL doesn't count records as requested")
        
        # Check for missing LIMIT in potentially large result sets
        if 'limit' not in sql_lower and 'count(' not in sql_lower:
            issues.append("SQL may return too many results (missing LIMIT)")
        
        return issues
    
    # ========================================================================
    # üìä CACHING SYSTEM
    # ========================================================================
    
    def _generate_cache_key(self, prompt: str, model: str) -> str:
        """Generate cache key for prompt and model combination"""
        import hashlib
        
        # Create hash from prompt + model
        content = f"{prompt}|{model}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def _get_cached_response(self, cache_key: str) -> Optional[str]:
        """Get cached response if available and valid"""
        
        if cache_key not in self.response_cache:
            return None
        
        cache_entry = self.response_cache[cache_key]
        
        # Check if cache is still valid
        cache_age = time.time() - cache_entry['timestamp']
        if cache_age > self.cache_ttl:
            del self.response_cache[cache_key]
            return None
        
        logger.info(f"üöÄ Using cached AI response (age: {cache_age:.1f}s)")
        return cache_entry['response']
    
    def _cache_response(self, cache_key: str, response: str):
        """Cache AI response"""
        
        # Limit cache size
        if len(self.response_cache) > 100:
            # Remove oldest entries
            oldest_keys = sorted(
                self.response_cache.keys(),
                key=lambda k: self.response_cache[k]['timestamp']
            )[:20]
            
            for key in oldest_keys:
                del self.response_cache[key]
        
        self.response_cache[cache_key] = {
            'response': response,
            'timestamp': time.time()
        }
    
    def clear_cache(self):
        """Clear all cached responses"""
        self.response_cache.clear()
        logger.info("üßπ AI response cache cleared")
    
    # ========================================================================
    # üìä PERFORMANCE MONITORING
    # ========================================================================
    
    def _update_performance_stats(self, tenant_id: str, execution_time: float, 
                                 success: bool, cache_hit: bool):
        """Update performance statistics"""
        
        # Update global stats
        self.performance_stats['total_requests'] += 1
        
        if success:
            self.performance_stats['successful_requests'] += 1
        else:
            self.performance_stats['failed_requests'] += 1
        
        if cache_hit:
            self.performance_stats['cache_hits'] += 1
        
        # Update average response time
        total_requests = self.performance_stats['total_requests']
        current_avg = self.performance_stats['avg_response_time']
        new_avg = ((current_avg * (total_requests - 1)) + execution_time) / total_requests
        self.performance_stats['avg_response_time'] = new_avg
        
        # Update tenant-specific stats
        if tenant_id not in self.performance_stats['tenant_breakdown']:
            self.performance_stats['tenant_breakdown'][tenant_id] = {
                'requests': 0,
                'successes': 0,
                'failures': 0,
                'cache_hits': 0,
                'avg_response_time': 0
            }
        
        tenant_stats = self.performance_stats['tenant_breakdown'][tenant_id]
        tenant_stats['requests'] += 1
        
        if success:
            tenant_stats['successes'] += 1
        else:
            tenant_stats['failures'] += 1
        
        if cache_hit:
            tenant_stats['cache_hits'] += 1
        
        # Update tenant average response time
        tenant_requests = tenant_stats['requests']
        tenant_current_avg = tenant_stats['avg_response_time']
        tenant_new_avg = ((tenant_current_avg * (tenant_requests - 1)) + execution_time) / tenant_requests
        tenant_stats['avg_response_time'] = tenant_new_avg
    
    def get_performance_stats(self, tenant_id: str = None) -> Dict[str, Any]:
        """Get performance statistics"""
        
        if tenant_id and tenant_id in self.performance_stats['tenant_breakdown']:
            tenant_stats = self.performance_stats['tenant_breakdown'][tenant_id]
            success_rate = (tenant_stats['successes'] / tenant_stats['requests'] * 100) if tenant_stats['requests'] > 0 else 0
            cache_hit_rate = (tenant_stats['cache_hits'] / tenant_stats['requests'] * 100) if tenant_stats['requests'] > 0 else 0
            
            return {
                'tenant_id': tenant_id,
                'requests': tenant_stats['requests'],
                'success_rate': round(success_rate, 2),
                'cache_hit_rate': round(cache_hit_rate, 2),
                'avg_response_time': round(tenant_stats['avg_response_time'], 3)
            }
        else:
            total_requests = self.performance_stats['total_requests']
            success_rate = (self.performance_stats['successful_requests'] / total_requests * 100) if total_requests > 0 else 0
            cache_hit_rate = (self.performance_stats['cache_hits'] / total_requests * 100) if total_requests > 0 else 0
            
            return {
                'total_requests': total_requests,
                'success_rate': round(success_rate, 2),
                'cache_hit_rate': round(cache_hit_rate, 2),
                'avg_response_time': round(self.performance_stats['avg_response_time'], 3),
                'tenant_breakdown': self.performance_stats['tenant_breakdown']
            }
    
    # ========================================================================
    # üîß HEALTH CHECK AND DIAGNOSTICS
    # ========================================================================
    
    async def health_check(self) -> Dict[str, Any]:
        """Comprehensive health check for AI service"""
        
        health_status = {
            'status': 'unknown',
            'ollama_server': {},
            'model_availability': {},
            'performance_metrics': {},
            'cache_status': {},
            'last_check': datetime.now().isoformat()
        }
        
        try:
            # Test basic connectivity
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.ollama_base_url}/api/tags",
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    
                    if response.status == 200:
                        models_data = await response.json()
                        available_models = [model['name'] for model in models_data.get('models', [])]
                        
                        health_status['ollama_server'] = {
                            'status': 'healthy',
                            'url': self.ollama_base_url,
                            'response_time': '< 10s'
                        }
                        
                        health_status['model_availability'] = {
                            'available_models': available_models,
                            'configured_models': list(self.model_configs.keys()),
                            'missing_models': [
                                model for model in self.model_configs.keys() 
                                if model not in available_models
                            ]
                        }
                        
                        # Test a simple query
                        test_result = await self._test_model_functionality()
                        health_status['model_test'] = test_result
                        
                        # Overall status determination
                        if not health_status['model_availability']['missing_models'] and test_result['success']:
                            health_status['status'] = 'healthy'
                        else:
                            health_status['status'] = 'degraded'
                    else:
                        health_status['ollama_server'] = {
                            'status': 'unhealthy',
                            'error': f"HTTP {response.status}"
                        }
                        health_status['status'] = 'unhealthy'
                        
        except asyncio.TimeoutError:
            health_status['ollama_server'] = {
                'status': 'unhealthy',
                'error': 'Connection timeout'
            }
            health_status['status'] = 'unhealthy'
        except Exception as e:
            health_status['ollama_server'] = {
                'status': 'unhealthy',
                'error': str(e)
            }
            health_status['status'] = 'unhealthy'
        
        # Add performance metrics
        health_status['performance_metrics'] = self.get_performance_stats()
        
        # Add cache status
        health_status['cache_status'] = {
            'cached_responses': len(self.response_cache),
            'cache_ttl': self.cache_ttl
        }
        
        return health_status
    
    async def _test_model_functionality(self) -> Dict[str, Any]:
        """Test basic model functionality"""
        
        try:
            # Create a simple test config
            from .tenant_config import TenantConfig
            test_config = TenantConfig(
                tenant_id='test',
                name='Test',
                db_host='test',
                db_port=5432,
                db_name='test',
                db_user='test',
                db_password='test',
                model_name='llama3.1:8b',
                language='th',
                business_type='test',
                key_metrics=[]
            )
            
            test_prompt = "Generate a simple SELECT SQL query to get employee names."
            response = await self.call_ollama_api(test_config, test_prompt, temperature=0.1)
            
            # Check if response contains SQL
            has_sql = 'SELECT' in response.upper()
            
            return {
                'success': True,
                'response_length': len(response),
                'contains_sql': has_sql,
                'model_responsive': True
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'model_responsive': False
            }
    
    # ========================================================================
    # üîß UTILITY METHODS
    # ========================================================================
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """Get configuration for specific model"""
        return self.model_configs.get(model_name, self.model_configs['llama3.1:8b'])
    
    def add_model_config(self, model_name: str, config: Dict[str, Any]):
        """Add new model configuration"""
        self.model_configs[model_name] = config
        logger.info(f"‚úÖ Added model configuration for {model_name}")
    
    def optimize_for_tenant(self, tenant_config: TenantConfig) -> Dict[str, Any]:
        """Get optimized settings for specific tenant"""
        
        # Business type specific optimizations
        optimizations = {
            'enterprise_software': {
                'temperature': 0.1,  # More precise for technical queries
                'top_p': 0.8,
                'emphasis': 'accuracy'
            },
            'tourism_hospitality': {
                'temperature': 0.2,  # Slightly more creative for tourism
                'top_p': 0.85,
                'emphasis': 'cultural_awareness'
            },
            'global_operations': {
                'temperature': 0.15,  # Balanced for international context
                'top_p': 0.9,
                'emphasis': 'multilingual_accuracy'
            }
        }
        
        return optimizations.get(tenant_config.business_type, optimizations['enterprise_software'])

# Create alias for backward compatibility
AIService = EnhancedAIService

# Also export both names
__all__ = ['EnhancedAIService', 'AIService']# refactored_modules/ai_service.py
# ü§ñ Enhanced AI/Ollama Communication Service with Smart Prompt Engineering

