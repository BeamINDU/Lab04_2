# refactored_modules/intelligent_schema_discovery_fixed.py
# ğŸ”§ à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¹€à¸ˆà¸­

import time
import re
from typing import Dict, List, Any, Optional, Tuple
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class IntelligentSchemaDiscovery:
    """ğŸ§  Fixed version - à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"""
    
    def __init__(self, database_handler):
        self.db_handler = database_handler
        
        # à¹€à¸à¹‡à¸š cache à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¹à¸¥à¹‰à¸§
        self.learned_schemas = {
            'departments': {},
            'positions': {},
            'projects': {},
            'relationships': {}
        }
        
        self.cache_timestamps = {}
        self.cache_duration = 1800  # 30 à¸™à¸²à¸—à¸µ
        
        logger.info("ğŸ§  Fixed Intelligent Schema Discovery system initialized")
    
    async def get_contextual_schema(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """ğŸ¯ Main function - Fixed version"""
        
        # à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸³à¸–à¸²à¸¡
        question_analysis = self._analyze_question_deeply(question)
        logger.info(f"ğŸ” Question analysis result: {question_analysis}")
        
        # à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
        required_data = await self._gather_required_data(tenant_id, question_analysis)
        
        # à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 3: à¸ªà¸£à¹‰à¸²à¸‡ schema context
        contextual_schema = self._build_intelligent_context(question_analysis, required_data, tenant_id)
        
        return contextual_schema
    
    def _analyze_question_deeply(self, question: str) -> Dict[str, Any]:
        """ğŸ” Fixed question analysis"""
        
        question_lower = question.lower()
        
        analysis_result = {
            'question_type': 'unknown',
            'main_entities': [],
            'specific_keywords': [],
            'needs_relationships': False,
            'needs_counting': False,
            'needs_filtering': False,
            'confidence_level': 0.0
        }
        
        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸³à¸–à¸²à¸¡
        if any(word in question_lower for word in ['à¸à¸µà¹ˆà¸„à¸™', 'à¸ˆà¸³à¸™à¸§à¸™', 'à¸™à¸±à¸š', 'how many', 'count']):
            analysis_result['question_type'] = 'counting'
            analysis_result['needs_counting'] = True
            analysis_result['confidence_level'] += 0.3
        
        elif any(word in question_lower for word in ['à¹ƒà¸„à¸£', 'à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­', 'à¹à¸ªà¸”à¸‡', 'list', 'show', 'who']):
            analysis_result['question_type'] = 'listing'
            analysis_result['confidence_level'] += 0.3
        
        elif any(word in question_lower for word in ['à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸š', 'à¸—à¸³à¸‡à¸²à¸™', 'assigned', 'working', 'responsible']):
            analysis_result['question_type'] = 'relationship'
            analysis_result['needs_relationships'] = True
            analysis_result['confidence_level'] += 0.4
        
        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ entities à¸«à¸¥à¸±à¸
        if any(word in question_lower for word in ['à¹à¸œà¸™à¸', 'department', 'à¸à¹ˆà¸²à¸¢']):
            analysis_result['main_entities'].append('departments')
            analysis_result['confidence_level'] += 0.2
            
            # à¸«à¸²à¸„à¸³à¸ªà¸³à¸„à¸±à¸à¹€à¸‰à¸à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸œà¸™à¸
            if any(keyword in question_lower for keyword in ['it', 'à¹„à¸­à¸—à¸µ', 'à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ', 'technology', 'information']):
                analysis_result['specific_keywords'].append('department_it')
        
        if any(word in question_lower for word in ['à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡', 'position', 'à¸‡à¸²à¸™', 'job']):
            analysis_result['main_entities'].append('positions')
            analysis_result['confidence_level'] += 0.2
            
            # à¸«à¸²à¸„à¸³à¸ªà¸³à¸„à¸±à¸à¹€à¸‰à¸à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡
            position_keywords = ['developer', 'frontend', 'backend', 'designer', 'manager']
            for keyword in position_keywords:
                if keyword in question_lower:
                    analysis_result['specific_keywords'].append(f'position_{keyword}')
        
        if any(word in question_lower for word in ['à¹‚à¸›à¸£à¹€à¸ˆà¸„', 'project', 'à¸‡à¸²à¸™', 'à¸£à¸°à¸šà¸š']):
            analysis_result['main_entities'].append('projects')
            analysis_result['confidence_level'] += 0.2
        
        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ filtering
        if any(word in question_lower for word in ['à¸—à¸µà¹ˆ', 'à¹ƒà¸™', 'à¸‚à¸­à¸‡', 'where', 'in', 'with']):
            analysis_result['needs_filtering'] = True
        
        return analysis_result
    
    async def _gather_required_data(self, tenant_id: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ“Š Fixed data gathering with proper error handling"""
        
        required_data = {}
        
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¸ à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™
        if 'departments' in analysis['main_entities']:
            try:
                required_data['departments'] = await self._get_department_data(tenant_id, analysis)
            except Exception as e:
                logger.error(f"Failed to get department data: {e}")
                required_data['departments'] = self._get_fallback_department_data()
        
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™
        if 'positions' in analysis['main_entities']:
            try:
                required_data['positions'] = await self._get_position_data(tenant_id, analysis)
            except Exception as e:
                logger.error(f"Failed to get position data: {e}")
                required_data['positions'] = self._get_fallback_position_data()
        
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸›à¸£à¹€à¸ˆà¸„ à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™ - ğŸ†• Fixed
        if 'projects' in analysis['main_entities']:
            try:
                required_data['projects'] = await self._get_project_data(tenant_id, analysis)
            except Exception as e:
                logger.error(f"Failed to get project data: {e}")
                required_data['projects'] = self._get_fallback_project_data()
        
        # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™
        if analysis['needs_relationships']:
            try:
                required_data['relationships'] = await self._get_relationship_patterns(tenant_id)
            except Exception as e:
                logger.error(f"Failed to get relationship data: {e}")
                required_data['relationships'] = {'has_relationships': False}
        
        return required_data
    
    async def _get_department_data(self, tenant_id: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ¢ Fixed department data fetching"""
        
        cache_key = f"{tenant_id}_departments"
        if self._is_cache_valid(cache_key):
            logger.info(f"ğŸ“Š Using cached department data for {tenant_id}")
            return self.learned_schemas['departments'][tenant_id]
        
        try:
            # ğŸ”§ Fixed: à¹ƒà¸Šà¹‰ _get_database_connection à¹à¸—à¸™ get_database_connection
            conn = self.db_handler._get_database_connection(tenant_id)
            cursor = conn.cursor()
            
            department_data = {
                'all_departments': [],
                'relevant_departments': [],
                'department_stats': {}
            }
            
            # à¸”à¸¶à¸‡à¹à¸œà¸™à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸à¸£à¹‰à¸­à¸¡à¸ˆà¸³à¸™à¸§à¸™à¸à¸™à¸±à¸à¸‡à¸²à¸™
            cursor.execute("""
                SELECT department, COUNT(*) as employee_count, AVG(salary) as avg_salary
                FROM employees 
                GROUP BY department 
                ORDER BY employee_count DESC
            """)
            
            for row in cursor.fetchall():
                dept_name, count, avg_salary = row
                department_data['all_departments'].append(dept_name)
                department_data['department_stats'][dept_name] = {
                    'employee_count': count,
                    'avg_salary': float(avg_salary) if avg_salary else 0
                }
            
            # à¸«à¸²à¸à¸¡à¸µ keyword à¹€à¸‰à¸à¸²à¸° à¹ƒà¸«à¹‰à¸«à¸²à¹à¸œà¸™à¸à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
            if analysis['specific_keywords']:
                for keyword in analysis['specific_keywords']:
                    if keyword.startswith('department_'):
                        dept_type = keyword.replace('department_', '')
                        relevant_depts = self._find_matching_departments(
                            department_data['all_departments'], dept_type
                        )
                        department_data['relevant_departments'].extend(relevant_depts)
            
            cursor.close()
            conn.close()
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸¥à¸‡ cache
            self.learned_schemas['departments'][tenant_id] = department_data
            self.cache_timestamps[cache_key] = time.time()
            
            logger.info(f"âœ… Loaded department data for {tenant_id}: {len(department_data['all_departments'])} departments")
            return department_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to get department data for {tenant_id}: {e}")
            return self._get_fallback_department_data()
    
    async def _get_position_data(self, tenant_id: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ‘” Fixed position data fetching"""
        
        cache_key = f"{tenant_id}_positions"
        if self._is_cache_valid(cache_key):
            return self.learned_schemas['positions'][tenant_id]
        
        try:
            # ğŸ”§ Fixed: à¹ƒà¸Šà¹‰ _get_database_connection
            conn = self.db_handler._get_database_connection(tenant_id)
            cursor = conn.cursor()
            
            position_data = {
                'all_positions': [],
                'relevant_positions': [],
                'position_stats': {}
            }
            
            # à¸”à¸¶à¸‡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸à¸£à¹‰à¸­à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸–à¸´à¸•à¸´
            cursor.execute("""
                SELECT position, COUNT(*) as position_count, 
                       AVG(salary) as avg_salary, department
                FROM employees 
                GROUP BY position, department 
                ORDER BY position_count DESC
            """)
            
            for row in cursor.fetchall():
                position, count, avg_salary, department = row
                if position not in position_data['all_positions']:
                    position_data['all_positions'].append(position)
                
                position_data['position_stats'][position] = {
                    'count': count,
                    'avg_salary': float(avg_salary) if avg_salary else 0,
                    'department': department
                }
            
            # à¸«à¸²à¸à¸¡à¸µ keyword à¹€à¸‰à¸à¸²à¸° à¹ƒà¸«à¹‰à¸«à¸²à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
            if analysis['specific_keywords']:
                for keyword in analysis['specific_keywords']:
                    if keyword.startswith('position_'):
                        pos_type = keyword.replace('position_', '')
                        relevant_positions = self._find_matching_positions(
                            position_data['all_positions'], pos_type
                        )
                        position_data['relevant_positions'].extend(relevant_positions)
            
            cursor.close()
            conn.close()
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸¥à¸‡ cache
            self.learned_schemas['positions'][tenant_id] = position_data
            self.cache_timestamps[cache_key] = time.time()
            
            return position_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to get position data for {tenant_id}: {e}")
            return self._get_fallback_position_data()
    
    async def _get_project_data(self, tenant_id: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ“‹ ğŸ†• Added missing project data method"""
        
        cache_key = f"{tenant_id}_projects"
        if self._is_cache_valid(cache_key):
            return self.learned_schemas['projects'][tenant_id]
        
        try:
            conn = self.db_handler._get_database_connection(tenant_id)
            cursor = conn.cursor()
            
            project_data = {
                'all_projects': [],
                'project_stats': {}
            }
            
            # à¸”à¸¶à¸‡à¹‚à¸›à¸£à¹€à¸ˆà¸„à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
            cursor.execute("""
                SELECT name, client, budget, status
                FROM projects 
                ORDER BY budget DESC
                LIMIT 20
            """)
            
            for row in cursor.fetchall():
                project_name, client, budget, status = row
                project_data['all_projects'].append(project_name)
                project_data['project_stats'][project_name] = {
                    'client': client,
                    'budget': float(budget) if budget else 0,
                    'status': status
                }
            
            cursor.close()
            conn.close()
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸¥à¸‡ cache
            self.learned_schemas['projects'][tenant_id] = project_data
            self.cache_timestamps[cache_key] = time.time()
            
            return project_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to get project data for {tenant_id}: {e}")
            return self._get_fallback_project_data()
    
    async def _get_relationship_patterns(self, tenant_id: str) -> Dict[str, Any]:
        """ğŸ¤ Fixed relationship data fetching"""
        
        cache_key = f"{tenant_id}_relationships"
        if self._is_cache_valid(cache_key):
            return self.learned_schemas['relationships'][tenant_id]
        
        try:
            conn = self.db_handler._get_database_connection(tenant_id)
            cursor = conn.cursor()
            
            relationship_data = {
                'employee_project_count': 0,
                'unique_roles': [],
                'allocation_patterns': {},
                'has_relationships': False
            }
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
            cursor.execute("SELECT COUNT(*) FROM employee_projects")
            count = cursor.fetchone()[0]
            relationship_data['employee_project_count'] = count
            relationship_data['has_relationships'] = count > 0
            
            if count > 0:
                # à¸”à¸¶à¸‡à¸šà¸—à¸šà¸²à¸—à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ
                cursor.execute("SELECT DISTINCT role FROM employee_projects ORDER BY role")
                relationship_data['unique_roles'] = [row[0] for row in cursor.fetchall()]
            
            cursor.close()
            conn.close()
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸¥à¸‡ cache
            self.learned_schemas['relationships'][tenant_id] = relationship_data
            self.cache_timestamps[cache_key] = time.time()
            
            return relationship_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to get relationship data for {tenant_id}: {e}")
            return {'has_relationships': False, 'employee_project_count': 0}
    
    def _find_matching_departments(self, all_departments: List[str], dept_type: str) -> List[str]:
        """ğŸ” à¸«à¸²à¹à¸œà¸™à¸à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸š keyword"""
        
        matching_departments = []
        
        patterns = {
            'it': ['information', 'technology', 'it', 'à¹„à¸­à¸—à¸µ', 'à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ'],
            'sales': ['sales', 'marketing', 'à¸‚à¸²à¸¢', 'à¸à¸²à¸£à¸•à¸¥à¸²à¸”'],
            'management': ['management', 'à¸ˆà¸±à¸”à¸à¸²à¸£', 'à¸šà¸£à¸´à¸«à¸²à¸£', 'à¸œà¸¹à¹‰à¸šà¸£à¸´à¸«à¸²à¸£']
        }
        
        if dept_type in patterns:
            search_patterns = patterns[dept_type]
            
            for department in all_departments:
                dept_lower = department.lower()
                if any(pattern in dept_lower for pattern in search_patterns):
                    matching_departments.append(department)
        
        return matching_departments
    
    def _find_matching_positions(self, all_positions: List[str], pos_type: str) -> List[str]:
        """ğŸ” à¸«à¸²à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸š keyword"""
        
        matching_positions = []
        
        patterns = {
            'developer': ['developer', 'dev', 'programmer', 'à¹‚à¸›à¸£à¹à¸à¸£à¸¡', 'à¸à¸±à¸’à¸™à¸²'],
            'frontend': ['frontend', 'front-end', 'à¸«à¸™à¹‰à¸²à¸šà¹‰à¸²à¸™'],
            'backend': ['backend', 'back-end', 'à¸«à¸¥à¸±à¸‡à¸šà¹‰à¸²à¸™'],
            'designer': ['designer', 'design', 'à¸­à¸­à¸à¹à¸šà¸š', 'à¸”à¸µà¹„à¸‹à¸™à¹Œ'],
            'manager': ['manager', 'à¸œà¸ˆà¸', 'à¸œà¸¹à¹‰à¸ˆà¸±à¸”à¸à¸²à¸£', 'à¸«à¸±à¸§à¸«à¸™à¹‰à¸²']
        }
        
        if pos_type in patterns:
            search_patterns = patterns[pos_type]
            
            for position in all_positions:
                pos_lower = position.lower()
                if any(pattern in pos_lower for pattern in search_patterns):
                    matching_positions.append(position)
        
        return matching_positions
    
    def _build_intelligent_context(self, analysis: Dict[str, Any], 
                                 required_data: Dict[str, Any], tenant_id: str) -> Dict[str, Any]:
        """ğŸ¯ à¸ªà¸£à¹‰à¸²à¸‡ context à¸—à¸µà¹ˆà¸Šà¸²à¸à¸‰à¸¥à¸²à¸”"""
        
        context = {
            'schema_type': 'intelligent_contextual',
            'question_analysis': analysis,
            'discovered_at': datetime.now().isoformat(),
            'tenant_id': tenant_id,
            'guidance': {},
            'specific_data': {}
        }
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹€à¸‰à¸à¸²à¸°
        if analysis['question_type'] == 'counting':
            context['guidance']['query_type'] = 'COUNT query required'
            context['guidance']['sql_hints'] = [
                'à¹ƒà¸Šà¹‰ COUNT(*) à¸ªà¸³à¸«à¸£à¸±à¸šà¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™',
                'à¹ƒà¸Šà¹‰ GROUP BY à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡',
                'à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ JOIN à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸•à¸²à¸£à¸²à¸‡ employees à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™'
            ]
        
        elif analysis['question_type'] == 'relationship':
            context['guidance']['query_type'] = 'JOIN query required'
            context['guidance']['sql_hints'] = [
                'à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ JOIN à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ employees, employee_projects, à¹à¸¥à¸° projects',
                'à¹ƒà¸Šà¹‰ e.id = ep.employee_id à¹à¸¥à¸° ep.project_id = p.id',
                'à¹€à¸¥à¸·à¸­à¸à¸Ÿà¸´à¸¥à¸”à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡: e.name, p.name, ep.role'
            ]
        
        # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸à¸²à¸°à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
        if 'departments' in required_data:
            dept_data = required_data['departments']
            if dept_data['relevant_departments']:
                context['specific_data']['departments'] = dept_data['relevant_departments']
            else:
                context['specific_data']['departments'] = dept_data['all_departments']
        
        if 'positions' in required_data:
            pos_data = required_data['positions']
            if pos_data['relevant_positions']:
                context['specific_data']['positions'] = pos_data['relevant_positions']
            else:
                context['specific_data']['positions'] = pos_data['all_positions'][:10]
        
        if 'relationships' in required_data:
            rel_data = required_data['relationships']
            context['specific_data']['has_employee_projects'] = rel_data['has_relationships']
            if rel_data['has_relationships']:
                context['specific_data']['available_roles'] = rel_data['unique_roles']
        
        return context
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """â° à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š cache validity"""
        if cache_key not in self.cache_timestamps:
            return False
        
        cache_age = time.time() - self.cache_timestamps[cache_key]
        return cache_age < self.cache_duration
    
    def _get_fallback_department_data(self) -> Dict[str, Any]:
        """ğŸ”„ Fallback department data"""
        logger.warning("âš ï¸ Using fallback department data")
        return {
            'all_departments': ['Information Technology', 'Sales & Marketing', 'Management'],
            'relevant_departments': [],
            'department_stats': {}
        }
    
    def _get_fallback_position_data(self) -> Dict[str, Any]:
        """ğŸ”„ Fallback position data"""
        logger.warning("âš ï¸ Using fallback position data")
        return {
            'all_positions': ['Frontend Developer', 'Backend Developer', 'Designer', 'Manager'],
            'relevant_positions': [],
            'position_stats': {}
        }
    
    def _get_fallback_project_data(self) -> Dict[str, Any]:
        """ğŸ”„ ğŸ†• Added fallback project data"""
        logger.warning("âš ï¸ Using fallback project data")
        return {
            'all_projects': ['CRM System', 'Mobile App', 'Website'],
            'project_stats': {}
        }


class IntelligentPromptBuilder:
    """ğŸ¯ Fixed Prompt Builder"""
    
    def __init__(self, tenant_configs):
        self.tenant_configs = tenant_configs
        logger.info("ğŸ¯ Fixed Intelligent Prompt Builder initialized")
    
    def build_contextual_prompt(self, question: str, tenant_id: str, 
                              intelligent_context: Dict[str, Any]) -> str:
        """ğŸ¯ Fixed contextual prompt building"""
        
        config = self.tenant_configs[tenant_id]
        analysis = intelligent_context.get('question_analysis', {})
        guidance = intelligent_context.get('guidance', {})
        specific_data = intelligent_context.get('specific_data', {})
        
        prompt_sections = []
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 1: à¸šà¸£à¸´à¸šà¸—à¸šà¸£à¸´à¸©à¸±à¸—
        prompt_sections.append(f"à¸„à¸¸à¸“à¸„à¸·à¸­ PostgreSQL Expert à¸ªà¸³à¸«à¸£à¸±à¸š {config.name}")
        prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 2: à¸šà¸£à¸´à¸šà¸—à¸˜à¸¸à¸£à¸à¸´à¸ˆ
        business_context = self._get_business_context(tenant_id)
        prompt_sections.append(business_context)
        prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 3: à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        prompt_sections.append("ğŸ“Š à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:")
        prompt_sections.append("â€¢ employees: id, name, department, position, salary, hire_date, email")
        prompt_sections.append("â€¢ projects: id, name, client, budget, status, start_date, end_date, tech_stack")
        prompt_sections.append("â€¢ employee_projects: employee_id, project_id, role, allocation")
        prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 4: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸à¸²à¸°à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
        if specific_data:
            prompt_sections.append("ğŸ¯ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸™à¸µà¹‰:")
            
            if 'departments' in specific_data and specific_data['departments']:
                dept_list = "', '".join(specific_data['departments'])
                prompt_sections.append(f"ğŸ¢ à¹à¸œà¸™à¸à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¸ˆà¸£à¸´à¸‡: '{dept_list}'")
            
            if 'positions' in specific_data and specific_data['positions']:
                pos_list = "', '".join(specific_data['positions'][:8])
                prompt_sections.append(f"ğŸ‘” à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡: '{pos_list}'")
            
            if 'has_employee_projects' in specific_data:
                if specific_data['has_employee_projects']:
                    prompt_sections.append("ğŸ¤ à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸à¸™à¸±à¸à¸‡à¸²à¸™-à¹‚à¸›à¸£à¹€à¸ˆà¸„")
                    if 'available_roles' in specific_data:
                        roles = "', '".join(specific_data['available_roles'][:5])
                        prompt_sections.append(f"ğŸ­ à¸šà¸—à¸šà¸²à¸—à¸—à¸µà¹ˆà¸¡à¸µ: '{roles}'")
                else:
                    prompt_sections.append("âš ï¸ à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸à¸™à¸±à¸à¸‡à¸²à¸™-à¹‚à¸›à¸£à¹€à¸ˆà¸„")
            
            prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 5: à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹€à¸‰à¸à¸²à¸°
        if guidance:
            prompt_sections.append("ğŸ¯ à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹€à¸‰à¸à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¸™à¸µà¹‰:")
            
            if 'query_type' in guidance:
                prompt_sections.append(f"â€¢ à¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸³à¸–à¸²à¸¡: {guidance['query_type']}")
            
            if 'sql_hints' in guidance:
                for hint in guidance['sql_hints']:
                    prompt_sections.append(f"â€¢ {hint}")
            
            prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 6: à¸à¸à¸ªà¸³à¸„à¸±à¸
        prompt_sections.append("ğŸ”§ à¸à¸à¸ªà¸³à¸„à¸±à¸:")
        prompt_sections.append("1. à¹ƒà¸Šà¹‰à¹€à¸‰à¸à¸²à¸°à¸Šà¸·à¹ˆà¸­à¹à¸œà¸™à¸/à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¸‚à¹‰à¸²à¸‡à¸šà¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™")
        prompt_sections.append("2. à¹ƒà¸Šà¹‰ ILIKE '%keyword%' à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²")
        prompt_sections.append("3. à¹ƒà¸Šà¹‰ LIMIT 20 à¹€à¸ªà¸¡à¸­")
        prompt_sections.append("4. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š syntax à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        
        if analysis.get('question_type') == 'counting':
            prompt_sections.append("5. à¹ƒà¸Šà¹‰ COUNT(*) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸™à¸±à¸š à¹à¸¥à¸° GROUP BY à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸à¸¥à¸¸à¹ˆà¸¡")
        elif analysis.get('question_type') == 'relationship':
            prompt_sections.append("5. à¹ƒà¸Šà¹‰ JOIN à¹€à¸¡à¸·à¹ˆà¸­à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸«à¸¥à¸²à¸¢à¸•à¸²à¸£à¸²à¸‡")
        else:
            prompt_sections.append("5. à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡ JOIN à¸«à¸²à¸à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™")
        
        prompt_sections.append("")
        
        # à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ 7: à¸„à¸³à¸–à¸²à¸¡à¹à¸¥à¸°à¸„à¸³à¸ªà¸±à¹ˆà¸‡
        prompt_sections.append(f"â“ à¸„à¸³à¸–à¸²à¸¡: {question}")
        prompt_sections.append("")
        prompt_sections.append("à¸ªà¸£à¹‰à¸²à¸‡ PostgreSQL query à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹à¸¥à¸°à¹à¸¡à¹ˆà¸™à¸¢à¸³:")
        
        return "\n".join(prompt_sections)
    
    def _get_business_context(self, tenant_id: str) -> str:
        """ğŸ¢ Business context"""
        contexts = {
            'company-a': """ğŸ¢ à¸šà¸£à¸´à¸šà¸—: à¸ªà¸³à¸™à¸±à¸à¸‡à¸²à¸™à¹ƒà¸«à¸à¹ˆ à¸à¸£à¸¸à¸‡à¹€à¸—à¸à¸¡à¸¯ - Enterprise Banking & E-commerce
ğŸ’° à¸‡à¸šà¸›à¸£à¸°à¸¡à¸²à¸“: 800K-3M+ à¸šà¸²à¸— | à¸¥à¸¹à¸à¸„à¹‰à¸²: à¸˜à¸™à¸²à¸„à¸²à¸£, à¸šà¸£à¸´à¸©à¸±à¸—à¹ƒà¸«à¸à¹ˆ""",

            'company-b': """ğŸ¨ à¸šà¸£à¸´à¸šà¸—: à¸ªà¸²à¸‚à¸²à¸ à¸²à¸„à¹€à¸«à¸™à¸·à¸­ à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ - Tourism & Hospitality
ğŸ’° à¸‡à¸šà¸›à¸£à¸°à¸¡à¸²à¸“: 300K-800K à¸šà¸²à¸— | à¸¥à¸¹à¸à¸„à¹‰à¸²: à¹‚à¸£à¸‡à¹à¸£à¸¡, à¸—à¹ˆà¸­à¸‡à¹€à¸—à¸µà¹ˆà¸¢à¸§""",

            'company-c': """ğŸŒ à¸šà¸£à¸´à¸šà¸—: International Office - Global Software Solutions
ğŸ’° à¸‡à¸šà¸›à¸£à¸°à¸¡à¸²à¸“: 1M-4M+ USD | à¸¥à¸¹à¸à¸„à¹‰à¸²: à¸šà¸£à¸´à¸©à¸±à¸—à¸‚à¹‰à¸²à¸¡à¸Šà¸²à¸•à¸´"""
        }
        
        return contexts.get(tenant_id, contexts['company-a'])


class EnhancedSchemaIntegration:
    """ğŸ”— Fixed Integration class"""
    
    def __init__(self, database_handler, tenant_configs):
        self.schema_discovery = IntelligentSchemaDiscovery(database_handler)
        self.prompt_builder = IntelligentPromptBuilder(tenant_configs)
        logger.info("ğŸ”— Fixed Enhanced Schema Integration initialized")
    
    async def generate_intelligent_sql_prompt(self, question: str, tenant_id: str) -> str:
        """ğŸ¯ Fixed intelligent prompt generation"""
        
        try:
            # à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 1: à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸«à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
            intelligent_context = await self.schema_discovery.get_contextual_schema(question, tenant_id)
            
            # à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸—à¸µà¹ˆ 2: à¸ªà¸£à¹‰à¸²à¸‡ prompt
            intelligent_prompt = self.prompt_builder.build_contextual_prompt(
                question, tenant_id, intelligent_context
            )
            
            logger.info(f"âœ… Generated intelligent prompt for {tenant_id}: {len(intelligent_prompt)} chars")
            return intelligent_prompt
            
        except Exception as e:
            logger.error(f"âŒ Failed to generate intelligent prompt: {e}")
            
            # fallback
            return self._create_fallback_prompt(question, tenant_id)
    
    def _create_fallback_prompt(self, question: str, tenant_id: str) -> str:
        """ğŸ”„ Fallback prompt"""
        
        return f"""à¸„à¸¸à¸“à¸„à¸·à¸­ PostgreSQL Expert

ğŸ“Š à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:
â€¢ employees: id, name, department, position, salary, hire_date, email
â€¢ projects: id, name, client, budget, status, start_date, end_date, tech_stack
â€¢ employee_projects: employee_id, project_id, role, allocation

ğŸ”§ à¸à¸à¸ªà¸³à¸„à¸±à¸:
1. à¹ƒà¸Šà¹‰ LIMIT 20
2. à¹ƒà¸Šà¹‰ ILIKE à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²
3. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š syntax à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
4. à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¹à¸œà¸™à¸à¸ˆà¸£à¸´à¸‡: 'Information Technology' (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ 'IT')

à¸„à¸³à¸–à¸²à¸¡: {question}

à¸ªà¸£à¹‰à¸²à¸‡ PostgreSQL query:"""